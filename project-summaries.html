<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>National COVID-19 Chest Image Database (NCCID) | Documentation</title><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="5"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/covid-chest-imaging-database/_next/static/css/72b169729be2b961.css" as="style"/><link rel="stylesheet" href="/covid-chest-imaging-database/_next/static/css/72b169729be2b961.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/covid-chest-imaging-database/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/covid-chest-imaging-database/_next/static/chunks/webpack-b332f1205e2d16c6.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/framework-5f4595e5518b5600.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/main-ce97b006e71c4ac5.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/pages/_app-c220796b45e9077c.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/103-db4430827edb81aa.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/234-541af733db807726.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/685-ac54af423154e38f.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/chunks/pages/%5Bslug%5D-7178813ab1fa653b.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/bmJIz1Sl1uRhvnnPo0YjL/_buildManifest.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/bmJIz1Sl1uRhvnnPo0YjL/_ssgManifest.js" defer=""></script><script src="/covid-chest-imaging-database/_next/static/bmJIz1Sl1uRhvnnPo0YjL/_middlewareManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@200;300;400;500;600;700&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuDyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuOKfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuI6fMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuGKYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuFuYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next" data-reactroot=""><div class="antialiased"><div class="min-h-full"><nav class="bg-blue-500"><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-6xl"><div class="flex justify-between py-6"><div class="flex"><a class="flex flex-col space-y-6 md:space-y-4 lg:space-y-0 lg:flex-row lg:items-center lg:space-x-2 flex-shrink-0 text-white" href="/covid-chest-imaging-database"><span><img class="h-10 w-auto" src="/covid-chest-imaging-database/logo-inverted.svg" alt="NCCID"/></span><span class="text-sm lg:text-lg">National COVID-19 Chest Image Database (NCCID)</span></a></div><div class="hidden md:flex"><div class="flex-1 flex items-center space-x-6"><form action="/covid-chest-imaging-database/search" method="GET" class="flex-1 justify-stretch relative"><div class="relative flex-1"><input type="text" name="q" placeholder="Search" class="w-full border-2 pr-16 border-transparent focus:ring-nhsuk-focus focus:ring-4 focus:border-white rounded sm:text-sm" value=""/><div class="absolute right-0 top-0 bottom-0"><button type="submit" class="w-full h-full flex-1 bg-gray-50 rounded-tr rounded-br px-3 text-blue-500 focus:bg-nhsuk-yellow focus:text-black "><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-6 h-6"><path fill-rule="evenodd" d="M8 4a4 4 0 100 8 4 4 0 000-8zM2 8a6 6 0 1110.89 3.476l4.817 4.817a1 1 0 01-1.414 1.414l-4.816-4.816A6 6 0 012 8z" clip-rule="evenodd"></path></svg></button></div></div></form><a target="_BLANK" class="rounded-full" href="https://github.com/nhsx/covid-chest-imaging-database"><svg class="w-10 h-10 flex-shrink-0 text-white" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 16" fill="none"><g clip-path="url(githublogo)"><path fill="currentColor" fill-rule="evenodd" d="M8.18391.249268C3.82241.249268.253906 3.81777.253906 8.17927c0 3.46933 2.279874 6.44313 5.451874 7.53353.3965.0991.49563-.1983.49563-.3965v-1.3878c-2.18075.4956-2.67638-.9912-2.67638-.9912-.3965-.8922-.89212-1.1895-.89212-1.1895-.69388-.4957.09912-.4957.09912-.4957.793.0992 1.1895.793 1.1895.793.69388 1.2887 1.88338.8922 2.27988.6939.09912-.4956.29737-.8921.49562-1.0904-1.78425-.1982-3.5685-.8921-3.5685-3.96496 0-.89212.29738-1.586.793-2.08162-.09912-.19825-.3965-.99125.09913-2.08163 0 0 .69387-.19825 2.18075.793.59475-.19825 1.28862-.29737 1.9825-.29737.69387 0 1.38775.09912 1.98249.29737 1.4869-.99125 2.1808-.793 2.1808-.793.3965 1.09038.1982 1.88338.0991 2.08163.4956.59475.793 1.28862.793 2.08162 0 3.07286-1.8834 3.66766-3.66764 3.86586.29737.3965.59474.8921.59474 1.586v2.1808c0 .1982.0991.4956.5948.3965 3.172-1.0904 5.4518-4.0642 5.4518-7.53353-.0991-4.3615-3.6676-7.930002-8.02909-7.930002z" clip-rule="evenodd" class="jsx-1651122719"></path></g><defs><clipPath id="githublogo"><path fill="transparent" d="M0 0h15.86v15.86H0z" transform="translate(.253906 .0493164)"></path></clipPath></defs></svg></a></div></div><div class="-mr-2 flex items-start md:hidden"><button class="bg-white inline-flex items-center justify-center p-2 text-nhsuk-text hover:bg-gray-100 focus:bg-nhsuk-yellow focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-nhsuk-yellow" id="headlessui-disclosure-button-undefined" type="button" aria-expanded="false"><span class="sr-only">Open main menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div><div class="hidden md:block"><div class="border-t border-white border-opacity-20"><nav class="flex flex-col space-y-2 md:space-y-0 md:flex-row md:space-x-6"><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/covid-chest-imaging-database">Overview</a><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/covid-chest-imaging-database/data-access">Technical Documentation</a><a class="md:border-b-4 md:pb-3 border-white font-semibold group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/covid-chest-imaging-database/nccid-collaborative">Other Information</a><a class="border-transparent group flex items-center px-4 py-4 border-l-4 md:border-l-0 text-white hover:underline text-base focus:bg-nhsuk-yellow focus:text-black focus:border-black md:focus:border-b-4 md:focus:pb-3" href="/covid-chest-imaging-database/experiments">Experiments</a></nav></div></div></div></nav><div class=""><main class="flex-1"><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-6xl"><div class="flex flex-col py-8 lg:flex-row lg:py-12"><div class="hidden lg:flex relative w-80 flex-shrink-0"><div class="-mt-6"><div class="sticky top-0 pt-6"><div class="flex-grow flex flex-col space-y-8"><div class="space-y-4"><div class="flex items-center space-x-3"><div><div class="bg-blue-500 rounded p-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-4 h-4 text-white"><path fill-rule="evenodd" d="M11.49 3.17c-.38-1.56-2.6-1.56-2.98 0a1.532 1.532 0 01-2.286.948c-1.372-.836-2.942.734-2.106 2.106.54.886.061 2.042-.947 2.287-1.561.379-1.561 2.6 0 2.978a1.532 1.532 0 01.947 2.287c-.836 1.372.734 2.942 2.106 2.106a1.532 1.532 0 012.287.947c.379 1.561 2.6 1.561 2.978 0a1.533 1.533 0 012.287-.947c1.372.836 2.942-.734 2.106-2.106a1.533 1.533 0 01.947-2.287c1.561-.379 1.561-2.6 0-2.978a1.532 1.532 0 01-.947-2.287c.836-1.372-.734-2.942-2.106-2.106a1.532 1.532 0 01-2.287-.947zM10 13a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path></svg></div></div><div><p class="font-semibold text-gray-400 uppercase tracking-wider text-xs">Technical Documentation</p></div></div><nav class="mb-4 space-y-1 border-l border-gray-200 ml-3"><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/data-access">Accessing the NCCID data</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/resources">Resources for data users</a></nav></div><div class="space-y-4"><div class="flex items-center space-x-3"><div><div class="bg-blue-500 rounded p-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-4 h-4 text-white"><path d="M9 4.804A7.968 7.968 0 005.5 4c-1.255 0-2.443.29-3.5.804v10A7.969 7.969 0 015.5 14c1.669 0 3.218.51 4.5 1.385A7.962 7.962 0 0114.5 14c1.255 0 2.443.29 3.5.804v-10A7.968 7.968 0 0014.5 4c-1.255 0-2.443.29-3.5.804V12a1 1 0 11-2 0V4.804z"></path></svg></div></div><div><p class="font-semibold text-gray-400 uppercase tracking-wider text-xs">Other Information</p></div></div><nav class="mb-4 space-y-1 border-l border-gray-200 ml-3"><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/nccid-collaborative">NCCID Collaborative</a><a class="underline font-medium -ml-1 pl-7 text-blue-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/project-summaries"><div class="flex absolute -left-1 top-1/2 -mt-2 rounded-full border w-4 h-4 bg-white p-px"><div class="rounded-full bg-blue-500 flex-1"></div></div>NCCID project summaries</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/performance-assessment-call">Performance Assessment Call</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/other-datasets">Links to other datasets</a><a class="text-gray-500 relative group flex items-center py-2 px-6 text-base" href="/covid-chest-imaging-database/stats">Training data statistics</a></nav></div></div></div></div></div><div class="lg:hidden flex flex-col mb-8"><button class="bg-gray-100 flex justify-center items-center p-4 text-gray-500 underline" id="headlessui-disclosure-button-undefined" type="button" aria-expanded="false">Show menu</button></div><div class="flex-1 space-y-10"><div class="prose max-w-none"><h1>NCCID Project Summaries</h1>
<p>The core of the NCCID initiative is to provide value to the public in
response to the COVID-19 crisis. For this reason, NCCID wishes to share
information on how the data is being utilised by approved institutions
and researcherts, to inform the wider community of patients, staff and
interested public.</p>
<p>Below is a list of the projects currently ongoing.</p>
<h2>University College London</h2>
<p>University College London plans to store the NCCID data in a highly
secure XNAT repository to enable imaging-based research at UCL Centre
for Medical Image Computing (CMIC). In particular, researchers at CMIC
will use these data to build artificial intelligence models to
automatically detect COVID-19 patients based on their CT or X-ray
images, such that, in the future, these images can be screened
automatically before doctors read them. This will significantly save
time in managing future outbreaks. The research also involves building
computational models to analyse the outcomes for those with confirmed
COVID-19 diagnosis, predicting best management for individual patients.
These predictions may shorten their hospital stay, reduce complications
and even save lives. Finally, the project will investigates methods to
deploy these developed models to local hospitals quickly and safely.</p>
<h2>University of Cambridge</h2>
<p>It is strongly believed that early detection of COVID-19 and
intervention leads to lower Covid-19 mortality because it enables
disease treatment via oxygen therapy and control of spread via
isolation. The diagnosis of COVID-19 must be confirmed by
reverse-transcription polymerase chain reaction (RT-PCR) or gene
sequencing for respiratory or blood specimens. However, testing the
general population is proving to be very challenging because of various
reasons including limitations of sample collection and transportation,
kit performance and availability, limitations in capacity, etc.</p>
<p>Chest scans could include x-rays, CT and MRI scans. Chest CT scans are
used to examine lung tissues and often used for further investigation
after an abnormal chest x-ray. Chest MRI scans provide a detailed
picture of the chest wall, heart, and blood vessels. These scans are
carried out routinely for a variety of medical reasons, including
preparation for surgery, annual follow-ups, accident and emergency, etc.
The creation of computer systems that can automatically process these
scans to detect and identify signs of Covid-19 can provide added value
for the NHS with no significant additional burden on staff, resources,
operational costs, etc. The development of these systems require the
implementation of cutting-edge image processing and artificial
intelligence technologies.</p>
<p>X-ray images and CT scans can also be useful in monitoring the
progression of Covid-19 patients as they can reveal if their lungs are
filled with sticky mucus that can lead to breathing problems and provide
a benchmark for comparisons with previous scans.</p>
<p>This project aims to find the visual signatures of Covid-19, as they
appear in chest scans, that can lead to accurate diagnostic and
prognosis for use in hospital settings. Automated imaging algorithms,
aided by advanced artificial intelligence techniques, can detect some of
the abnormal features appearing in these scans, such as ground glass
patterned areas, Ground glass, Crazy paving, Vascular dilatation,
Traction Bronchiectasis. These features are generally not specific to
Covid-19 and could be seen with other infections. Hence, it is important
to develop AI techniques to aid the imaging analysis to increase the
accuracy of diagnostic.</p>
<h2>University of Bradford</h2>
<p>Coronavirus Disease 2019 (COVID-19) is highly contagious, and severe
cases can lead to pneumonia and ultimately death. The diagnosis can be
confirmed by laboratory testing; however, the test has low sensitivity
which leads to late diagnosis and treatment. Chest X-rays and CT scans
provide valuable diagnostic and monitoring information that can
complement the laboratory and clinical data. In this project, we propose
to develop an open-source artificial intelligence tool that combines
chest imaging data and clinical data to support the diagnosis, triaging
and prognosis for COVID-19 in the UK. This will make clinical decisions
more efficient, accurate, timely, and potentially cheaper, leading to
better patient outcomes.</p>
<h2>Aidence</h2>
<p>Chest CT scans are used in hospitals across the globe to image the
severity of COVID-19 lung involvement and guide the appropriate patient
management. Artificial intelligence (AI) designed for radiologists can
increase the speed of reporting on these scans and support timely
patient triaging.</p>
<p>Aidence has set-up an international consortium, ICOVAI, to create an AI
solution for COVID-19 on chest CTs. The consortium is a collaboration
between clinical centers, hospitals, AI companies, and distribution
partners.</p>
<p>ICOVAI&#x27;s AI solution will automatically detect COVID-19 on chest CTs and
assess the extent of lung tissue affected. Its quantitative analysis can
be used to guide hospital management, such as bed capacity on wards, or
predicting the need for ICU care.</p>
<p>The consortium aims to reduce the workload and pressure that the medical
staff are facing during the pandemic. The software will be particularly
useful when test kits are absent or inconclusive, and when radiologists
are unavailable or lack specific COVID-19 training.</p>
<p>To train a well-performing model, ICOVAI is using high-quality datasets
from diverse CT scanners, hospitals, and countries. The patient data is
anonymised and processed in line with the GDPR. The product will comply
with the Medical Device Regulation (MDR), 2017/745, to ensure clinical
safety and quality.</p>
<p>The AI solution will be made available not-for-profit for the NHS and
European hospitals. The project is backed by the EU.</p>
<h2>City Data Science Institute</h2>
<p>The City Data Science Institute are using the NCCID dataset to develop
artificial intelligence systems that offer explainable decision making.
More specifically, we are investigating the key radiological findings of
Covid-19, how this can change over time, and how this differs from other
disease findings upon a chest X-ray. Using state-of-the-art generative
networks, we aim to learn more about the Covid-19 disease process and
facilitate medical decision making.</p>
<p>The chest X-ray is a readily available investigation and is useful in
the identification, severity assessment and monitoring of Covid-19. It
is more readily available than CT scanning and able to exclude other
important conditions that may present. The use of AI to assess chest
X-rays can facilitate medical staff and improve patient outcomes.</p>
<p>We have begun using a particular type of artificial intelligence model
that is able to learn what an X-ray should appear like if it were to be
healthy or more diseased. This will help the research community learn
about subtle disease features and can contribute to more accurate and
quicker automatic diagnostics. One of our main goals is for our system
to offer a counterfactual explanation as to why the artificial
intelligence has made certain decisions. This is vital in developing
safe and effective AI.</p>
<h2>Medical Analytica Ltd</h2>
<p>To test, evaluate and further finetune a software which can
automatically analyse Chest X-ray images to identify absence or presence
of features of COVID-19 infection. The software can detect other lung
conditions such as pneumonia caused by viral or bacterial infections.
The software is being further developed to identify other key conditions
such as lesion and enlarged heart. The software utilises a number of
mathematical models for image analysis and is capable of offering a high
confidence classification with minimum false positives or false
negatives.</p>
<p>Ultimate objective is integrating it into the NHS radiology reporting
workflow to provide a prompt computer aided prediction alongside the
radiologist&#x27;s own report. By providing an extra layer of support to the
clinical team, patient triage and access to appropriate treatment can be
speed up. Saving time, resources and most importantly, improving patient
experience.</p>
<p>Other application of the software is to provide preliminary / indicative
prediction to the primary care team in remote locations and community
hospitals to assist in identifying in the community cases which may need
urgent specialist attention in main hospitals.</p>
<h2>Universities of Brighton, Oxford, Glasgow, Lincoln and Sheffield</h2>
<p>Members of this collaboration were instrumental in winning first place
in
&#x27;<a href="https://devpost.com/software/europa-mapp-predicting-stopping-covid19-waves-pandemics">Coronahackathon</a>&#x27;
April 2020, for the development of Machine Learning (ML) and Artificial
Intelligence (AI) to predict patients with SARS-CoV-2 virus using full
blood count results. SARS-CoV-2 positive patients exhibit a
characteristic change in different parameters measured in simple and
rapid blood tests to a high accuracy, predicting the virus in regular
wards (93-94%) and those in the community (80-86%).</p>
<p>Our project will validate these initial results and enable use in
current hospital practice to screen patients and identify those needing
full diagnosis for SARS-CoV-2. Expertise in chest images, blood science
and modelling ML and AI will develop an innovative tool to upscale
screening to identify individuals for full rt-PCR testing of the virus
potentially up to one week earlier than rt-PCR, which will allow much
faster release of the country (and the world) from lockdown, protection
against future waves and future pandemics.</p>
<h2>Ashford and St Peter&#x27;s Hospitals NHS Foundation Trust</h2>
<p>Chest X-rays are often one of the first tests used to help guide doctors
with deciding how likely a patient is to have COVID-19 and also how
severe the infection is. We are aiming to see how accurate chest X-rays
are for detecting COVID-19 and telling doctors how severe the disease
is. We plan to answer this by having doctors specialising in X-rays
assess chest X-rays of patients in the national COVID-19 imaging
database and then compare this assessment to clinical details, such as
if they had COVID-19 and how well they did in hospital. We hope this
will give us a better understanding of chest X-ray accuracy in COVID-19
and appearances that are linked to COVID-19 or more severe infection. We
also additionally aim to use Neural networks (advanced computational
algorithms) on the chest X-rays in the database to see if these can be
used to automatically detect COVID-19 in chest X-rays. This research
will hopefully one day help with the development of clinical algorithms
and technology that can be used to speed up chest X-ray assessment for
COVID-19.</p>
<h2>Behold.ai</h2>
<p><a href="https://behold.ai/">Behold.ai</a> is currently operating existing services
within the NHS for the triage of chest X-rays based on the presence of
abnormalities, as determined by artificial intelligence algorithms. In
this study Behold.ai aims to achieve two key goals.</p>
<p>First, we aim to validate that an algorithm developed for the general
detection of abnormalities on plain-film chest X-rays can identify novel
forms of abnormality (such as COVID-19) despite being developed prior to
that pathology&#x27;s initial presentation (in this case, prior to February
2020). We propose that this will show that the use of existing AI-based
patient triage can assist healthcare systems in the efficient use of
resource and radiological capacity during high stress periods such as
pandemic flu, even when novel pathologies are present.</p>
<p>Secondly, in recognition of the increased utilisation of AI across
healthcare sectors, we aim to establish a set of best practices for
rapidly and regularly updating clinically deployed algorithms in order
to enable efficient &#x27;learning&#x27; of the characteristics of novel
pathologies. This will be validated by the ability of existing chest
X-ray models to learn the characteristics of COVID-19 as demonstrated in
the NCCID. We suggest that this work will ensure that the implementation
of AI into health systems improves future pandemic preparedness as well
as maximising responsiveness to population health.</p>
<h2>The Royal Surrey NHS Foundation Trust</h2>
<p>Chest imaging is increasingly used as an alternative method for
screening COVID-19, with high sensitivity compared to laboratory testing
methods. AI tools have the potential to enable fast and accurate
diagnosis from chest X-rays (CXR). However, several issues of image
quality have been identified as a limitation to the diagnostic
performance of CXR, for example, in images acquired on portable
machines, and where under-exposure occurs due to patient positioning or
patient BMI. Little is known about the impact of image-quality upon the
accuracy and sensitivity of AI algorithms, and we propose to investigate
this, having been significantly involved in the development of the NCCID
database, and having successfully led previous evaluations of AI tools,
for example for diagnosis in breast screening.</p>
<p>The aim of this study is to evaluate the impact of image quality on the
performance of AI models by analysing performance metrics during
training and validation using the NCCID dataset. Published, open-source
models shown to classify COVID-19 on CXR will be identified and the
best-performing algorithm selected by assessing performance on the NCCID
test dataset. The NCCID training and test datasets will be analysed
using existing image analysis tools developed in-house at RSNFT,
enabling the categorisation of the NCCID dataset according to image
quality, and the dataset will be stratified into datasets of different
image quality. The AI model will be retrained and tested on different
combinations of training and test data image-quality and the impact of
image-quality upon the accuracy and sensitivity of the model evaluated.</p>
<h2>Imperial College London</h2>
<p>Sarcopenia is defined as the loss of skeletal muscle mass or function,
is primarily a disease of the elderly and a marker of frailty.
Currently, physical fitness is assessed with performance status, however
this score is subject to interobserver variability. There is increasing
interest in the clinical importance of sarcopenia in a wide range of
malignancies such as lung, breast, upper GI and colorectal cancers,
however the relationship to patient outcome in COVID-19 has not been
evaluated. CT provides an objective and easily reproducible assessment
of skeletal muscle which has been validated in cancer patients. These
studies used a time consuming manual segmentation of skeletal muscle at
L3 (3rd lumbar vertebra level) which is not easily integrated into
patient care and radiology reports. The research team have already
developed a fully automated technique for measuring sarcopenia on CT at
L3. The aim of the study is to evaluate an objective fully automated
assessment of muscle area and adiposity using artificial intelligence
(AI) deep learning techniques on CT to determine whether these measures
are linked to patient outcome in COVID-19 patients.</p>
<h2>University of Greenwich - School of Computing and Mathematical Sciences</h2>
<p>The project deals with diagnosis of COVID-19 from chest CT scans, scan
series and x-rays, through a novel Deep Learning methodology. Its main
target is to support unification of the rather fragmented field in UK
and internationally, where projects train DL systems over specific
datasets, obtained in smaller local, or larger national frameworks, with
no proof of good generalisation over different datasets and different
clinical environments. It will achieve this through generation of a
portable framework for COVID-19 diagnosis, based on analysis of
information extracted from trained deep neural networks and adaptation
across different data cohorts and input modalities.</p>
<p>In this framework, the main systems that have been trained with chest
imaging examinations for diagnosis of COVID-19 in Greece will be tested
and adapted to the UK cohort of CT scans and x-rays. It will be examined
whether the systems trained in a European country (such as Greece)
perform also well when applied to data from UK patients. Either, or both
CT scans and x-rays will be provided as inputs to these systems, for
single modal, or multi-modal COVID-19 detection. Furthermore, it will be
investigated whether this performance gets improved, if the systems get
adapted to the UK cohort. Finally, a unification step will be
implemented, by merging both systems, i.e.,the original and the adapted
ones, also validating the good performance of the unified system on the
UK data Cohort. This will illustrate the portability of the developed
unified model across Greece and UK and will serve as pilot that can be
extended with more COVID-19 diagnosis models from other parts of Europe,
or elsewhere.</p>
<h2>Philips</h2>
<p>As healthcare systems around the world face unprecedented stress levels, support to the clinical teams responsible for diagnosis and treatment of COVID19 patients is a priority. Recently, Philips (Royal Philips N.V.) has developed an automatic AI-based processing application (called “CT Pulmo Auto Results”, released in the USA under FDA Emergency Use Authorization and under regulatory review in EU) to assist clinical teams in quantification of the level of COVID-19 pneumonia disease burden. With the objective to further improve and monitor the performance of the application as the current pandemic unfolds, Philips is currently testing its application in collaboration with healthcare stakeholders at multiple locations around the world. As AI-based algorithms are claimed to be dependent on the training cohort Philips looks seriously to evaluate on various different cohorts. Within that scope, the National COVID-19 Chest Imaging Database (NCCID) will be used to study the performance of the application in UK patient datasets. Although approved for use in UK, the regulatory approval CE marking was not based on a UK population. In light of regulatory changes with CE marking required in future submissions and new MHRA policies coming into effect we also wish to learn from the NHSx AI lab on how to work effectively together on future R&amp;D studies in the UK using this study as an example and to work out any challenges together. Furthermore, we would explore the combination of the CT-based imaging volumetric measurements with the collected non-imaging patient data for COVID-19 pneumonia characterization with the goal to explore correlations with clinical endpoints, such as admission to Intensive Care Units or duration of stay in nursing wards.</p>
<h2>Leeds</h2>
<p>A crucial element in controlling the spread of COVID-19 is effective screening and timely treatment. Early detection of COVID-19 allows for swift intervention with isolation and appropriate use of personal protective equipment improving NHS resource allocation. Current practice commonly relies on PCR testing for confirmation of the diagnosis which takes over 24 hours for results, which can have a sensitivity as low as 60-70%. A supplementary automated tool for early detection of COVID-19 patients based on radiology could be a crucial part of addressing these issues. A wide variety of deep learning models have already been developed to detect COVID-19 in chest X-ray. However, due to a previous scarcity of COVID-19 data, many of the models the models that have been published are at high risk of bias and lack sufficient evaluation. This project will rigorously evaluate existing deep learning models with the aim of identifying the approaches most suited to detecting COVID-19 in chest X-rays. In-depth appraisal of model performances will highlight the pitfalls associated with the problem domain and help guide future work.</p></div><div class="flex justify-between items-center"><div><a class="flex-shrink-0 inline-flex justify-center items-center px-4 py-3 text-lg duration-100 font-semibold rounded shadow-nhsuk-button focus:bg-nhsuk-focus focus:text-nhsuk-text active:shadow-none  bg-green-500 text-white hover:bg-green-600" href="/covid-chest-imaging-database/nccid-collaborative">Previous</a></div><div><a class="flex-shrink-0 inline-flex justify-center items-center px-4 py-3 text-lg duration-100 font-semibold rounded shadow-nhsuk-button focus:bg-nhsuk-focus focus:text-nhsuk-text active:shadow-none  bg-green-500 text-white hover:bg-green-600" href="/covid-chest-imaging-database/performance-assessment-call">Next</a></div></div></div></div></div></main></div></div><div class="bg-gray-200 text-gray-500 border-t-4 border-blue-500 py-8 md:py-10"><div class="mx-auto px-4 sm:px-6 lg:px-8 max-w-6xl"><div class="space-y-10 sm:space-y-6"><div class="flex flex-col space-y-6 md:space-y-0 md:space-x-10 md:flex-row md:justify-between md:items-start"><div class="space-y-2 md:space-y-0 -ml-4"><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database">Overview</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/data-access">Accessing the NCCID data</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/resources">Resources for data users</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/nccid-collaborative">NCCID Collaborative</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/project-summaries">NCCID project summaries</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/performance-assessment-call">Performance Assessment Call</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/other-datasets">Links to other datasets</a><a class="block md:inline-block underline px-4 pb-4" href="/covid-chest-imaging-database/stats">Training data statistics</a></div><div class="flex-shrink-0">© Copyright 2020 NHSX</div></div><div class="flex flex-col space-y-3 sm:flex-row sm:items-center sm:space-y-0 sm:space-x-3 text-base"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 483.2 195.7" height="17" width="41" focusable="false"><path fill="currentColor" d="M421.5 142.8V.1l-50.7 32.3v161.1h112.4v-50.7zm-122.3-9.6A47.12 47.12 0 0 1 221 97.8c0-26 21.1-47.1 47.1-47.1 16.7 0 31.4 8.7 39.7 21.8l42.7-27.2A97.63 97.63 0 0 0 268.1 0c-36.5 0-68.3 20.1-85.1 49.7A98 98 0 0 0 97.8 0C43.9 0 0 43.9 0 97.8s43.9 97.8 97.8 97.8c36.5 0 68.3-20.1 85.1-49.7a97.76 97.76 0 0 0 149.6 25.4l19.4 22.2h3v-87.8h-80l24.3 27.5zM97.8 145c-26 0-47.1-21.1-47.1-47.1s21.1-47.1 47.1-47.1 47.2 21 47.2 47S123.8 145 97.8 145"></path></svg><span class="">All content is available under the Open Government Licence v3.0, except where otherwise stated.</span></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"source":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      h1: \"h1\",\n      p: \"p\",\n      h2: \"h2\",\n      a: \"a\"\n    }, _provideComponents(), props.components);\n    return _jsxs(_Fragment, {\n      children: [_jsx(_components.h1, {\n        children: \"NCCID Project Summaries\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The core of the NCCID initiative is to provide value to the public in\\nresponse to the COVID-19 crisis. For this reason, NCCID wishes to share\\ninformation on how the data is being utilised by approved institutions\\nand researcherts, to inform the wider community of patients, staff and\\ninterested public.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Below is a list of the projects currently ongoing.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"University College London\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"University College London plans to store the NCCID data in a highly\\nsecure XNAT repository to enable imaging-based research at UCL Centre\\nfor Medical Image Computing (CMIC). In particular, researchers at CMIC\\nwill use these data to build artificial intelligence models to\\nautomatically detect COVID-19 patients based on their CT or X-ray\\nimages, such that, in the future, these images can be screened\\nautomatically before doctors read them. This will significantly save\\ntime in managing future outbreaks. The research also involves building\\ncomputational models to analyse the outcomes for those with confirmed\\nCOVID-19 diagnosis, predicting best management for individual patients.\\nThese predictions may shorten their hospital stay, reduce complications\\nand even save lives. Finally, the project will investigates methods to\\ndeploy these developed models to local hospitals quickly and safely.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"University of Cambridge\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"It is strongly believed that early detection of COVID-19 and\\nintervention leads to lower Covid-19 mortality because it enables\\ndisease treatment via oxygen therapy and control of spread via\\nisolation. The diagnosis of COVID-19 must be confirmed by\\nreverse-transcription polymerase chain reaction (RT-PCR) or gene\\nsequencing for respiratory or blood specimens. However, testing the\\ngeneral population is proving to be very challenging because of various\\nreasons including limitations of sample collection and transportation,\\nkit performance and availability, limitations in capacity, etc.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Chest scans could include x-rays, CT and MRI scans. Chest CT scans are\\nused to examine lung tissues and often used for further investigation\\nafter an abnormal chest x-ray. Chest MRI scans provide a detailed\\npicture of the chest wall, heart, and blood vessels. These scans are\\ncarried out routinely for a variety of medical reasons, including\\npreparation for surgery, annual follow-ups, accident and emergency, etc.\\nThe creation of computer systems that can automatically process these\\nscans to detect and identify signs of Covid-19 can provide added value\\nfor the NHS with no significant additional burden on staff, resources,\\noperational costs, etc. The development of these systems require the\\nimplementation of cutting-edge image processing and artificial\\nintelligence technologies.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"X-ray images and CT scans can also be useful in monitoring the\\nprogression of Covid-19 patients as they can reveal if their lungs are\\nfilled with sticky mucus that can lead to breathing problems and provide\\na benchmark for comparisons with previous scans.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"This project aims to find the visual signatures of Covid-19, as they\\nappear in chest scans, that can lead to accurate diagnostic and\\nprognosis for use in hospital settings. Automated imaging algorithms,\\naided by advanced artificial intelligence techniques, can detect some of\\nthe abnormal features appearing in these scans, such as ground glass\\npatterned areas, Ground glass, Crazy paving, Vascular dilatation,\\nTraction Bronchiectasis. These features are generally not specific to\\nCovid-19 and could be seen with other infections. Hence, it is important\\nto develop AI techniques to aid the imaging analysis to increase the\\naccuracy of diagnostic.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"University of Bradford\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Coronavirus Disease 2019 (COVID-19) is highly contagious, and severe\\ncases can lead to pneumonia and ultimately death. The diagnosis can be\\nconfirmed by laboratory testing; however, the test has low sensitivity\\nwhich leads to late diagnosis and treatment. Chest X-rays and CT scans\\nprovide valuable diagnostic and monitoring information that can\\ncomplement the laboratory and clinical data. In this project, we propose\\nto develop an open-source artificial intelligence tool that combines\\nchest imaging data and clinical data to support the diagnosis, triaging\\nand prognosis for COVID-19 in the UK. This will make clinical decisions\\nmore efficient, accurate, timely, and potentially cheaper, leading to\\nbetter patient outcomes.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Aidence\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Chest CT scans are used in hospitals across the globe to image the\\nseverity of COVID-19 lung involvement and guide the appropriate patient\\nmanagement. Artificial intelligence (AI) designed for radiologists can\\nincrease the speed of reporting on these scans and support timely\\npatient triaging.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Aidence has set-up an international consortium, ICOVAI, to create an AI\\nsolution for COVID-19 on chest CTs. The consortium is a collaboration\\nbetween clinical centers, hospitals, AI companies, and distribution\\npartners.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"ICOVAI's AI solution will automatically detect COVID-19 on chest CTs and\\nassess the extent of lung tissue affected. Its quantitative analysis can\\nbe used to guide hospital management, such as bed capacity on wards, or\\npredicting the need for ICU care.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The consortium aims to reduce the workload and pressure that the medical\\nstaff are facing during the pandemic. The software will be particularly\\nuseful when test kits are absent or inconclusive, and when radiologists\\nare unavailable or lack specific COVID-19 training.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"To train a well-performing model, ICOVAI is using high-quality datasets\\nfrom diverse CT scanners, hospitals, and countries. The patient data is\\nanonymised and processed in line with the GDPR. The product will comply\\nwith the Medical Device Regulation (MDR), 2017/745, to ensure clinical\\nsafety and quality.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The AI solution will be made available not-for-profit for the NHS and\\nEuropean hospitals. The project is backed by the EU.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"City Data Science Institute\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The City Data Science Institute are using the NCCID dataset to develop\\nartificial intelligence systems that offer explainable decision making.\\nMore specifically, we are investigating the key radiological findings of\\nCovid-19, how this can change over time, and how this differs from other\\ndisease findings upon a chest X-ray. Using state-of-the-art generative\\nnetworks, we aim to learn more about the Covid-19 disease process and\\nfacilitate medical decision making.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The chest X-ray is a readily available investigation and is useful in\\nthe identification, severity assessment and monitoring of Covid-19. It\\nis more readily available than CT scanning and able to exclude other\\nimportant conditions that may present. The use of AI to assess chest\\nX-rays can facilitate medical staff and improve patient outcomes.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"We have begun using a particular type of artificial intelligence model\\nthat is able to learn what an X-ray should appear like if it were to be\\nhealthy or more diseased. This will help the research community learn\\nabout subtle disease features and can contribute to more accurate and\\nquicker automatic diagnostics. One of our main goals is for our system\\nto offer a counterfactual explanation as to why the artificial\\nintelligence has made certain decisions. This is vital in developing\\nsafe and effective AI.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Medical Analytica Ltd\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"To test, evaluate and further finetune a software which can\\nautomatically analyse Chest X-ray images to identify absence or presence\\nof features of COVID-19 infection. The software can detect other lung\\nconditions such as pneumonia caused by viral or bacterial infections.\\nThe software is being further developed to identify other key conditions\\nsuch as lesion and enlarged heart. The software utilises a number of\\nmathematical models for image analysis and is capable of offering a high\\nconfidence classification with minimum false positives or false\\nnegatives.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Ultimate objective is integrating it into the NHS radiology reporting\\nworkflow to provide a prompt computer aided prediction alongside the\\nradiologist's own report. By providing an extra layer of support to the\\nclinical team, patient triage and access to appropriate treatment can be\\nspeed up. Saving time, resources and most importantly, improving patient\\nexperience.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Other application of the software is to provide preliminary / indicative\\nprediction to the primary care team in remote locations and community\\nhospitals to assist in identifying in the community cases which may need\\nurgent specialist attention in main hospitals.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Universities of Brighton, Oxford, Glasgow, Lincoln and Sheffield\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [\"Members of this collaboration were instrumental in winning first place\\nin\\n'\", _jsx(_components.a, {\n          href: \"https://devpost.com/software/europa-mapp-predicting-stopping-covid19-waves-pandemics\",\n          children: \"Coronahackathon\"\n        }), \"'\\nApril 2020, for the development of Machine Learning (ML) and Artificial\\nIntelligence (AI) to predict patients with SARS-CoV-2 virus using full\\nblood count results. SARS-CoV-2 positive patients exhibit a\\ncharacteristic change in different parameters measured in simple and\\nrapid blood tests to a high accuracy, predicting the virus in regular\\nwards (93-94%) and those in the community (80-86%).\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Our project will validate these initial results and enable use in\\ncurrent hospital practice to screen patients and identify those needing\\nfull diagnosis for SARS-CoV-2. Expertise in chest images, blood science\\nand modelling ML and AI will develop an innovative tool to upscale\\nscreening to identify individuals for full rt-PCR testing of the virus\\npotentially up to one week earlier than rt-PCR, which will allow much\\nfaster release of the country (and the world) from lockdown, protection\\nagainst future waves and future pandemics.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Ashford and St Peter's Hospitals NHS Foundation Trust\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Chest X-rays are often one of the first tests used to help guide doctors\\nwith deciding how likely a patient is to have COVID-19 and also how\\nsevere the infection is. We are aiming to see how accurate chest X-rays\\nare for detecting COVID-19 and telling doctors how severe the disease\\nis. We plan to answer this by having doctors specialising in X-rays\\nassess chest X-rays of patients in the national COVID-19 imaging\\ndatabase and then compare this assessment to clinical details, such as\\nif they had COVID-19 and how well they did in hospital. We hope this\\nwill give us a better understanding of chest X-ray accuracy in COVID-19\\nand appearances that are linked to COVID-19 or more severe infection. We\\nalso additionally aim to use Neural networks (advanced computational\\nalgorithms) on the chest X-rays in the database to see if these can be\\nused to automatically detect COVID-19 in chest X-rays. This research\\nwill hopefully one day help with the development of clinical algorithms\\nand technology that can be used to speed up chest X-ray assessment for\\nCOVID-19.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Behold.ai\"\n      }), \"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.a, {\n          href: \"https://behold.ai/\",\n          children: \"Behold.ai\"\n        }), \" is currently operating existing services\\nwithin the NHS for the triage of chest X-rays based on the presence of\\nabnormalities, as determined by artificial intelligence algorithms. In\\nthis study Behold.ai aims to achieve two key goals.\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"First, we aim to validate that an algorithm developed for the general\\ndetection of abnormalities on plain-film chest X-rays can identify novel\\nforms of abnormality (such as COVID-19) despite being developed prior to\\nthat pathology's initial presentation (in this case, prior to February\\n2020). We propose that this will show that the use of existing AI-based\\npatient triage can assist healthcare systems in the efficient use of\\nresource and radiological capacity during high stress periods such as\\npandemic flu, even when novel pathologies are present.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Secondly, in recognition of the increased utilisation of AI across\\nhealthcare sectors, we aim to establish a set of best practices for\\nrapidly and regularly updating clinically deployed algorithms in order\\nto enable efficient 'learning' of the characteristics of novel\\npathologies. This will be validated by the ability of existing chest\\nX-ray models to learn the characteristics of COVID-19 as demonstrated in\\nthe NCCID. We suggest that this work will ensure that the implementation\\nof AI into health systems improves future pandemic preparedness as well\\nas maximising responsiveness to population health.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"The Royal Surrey NHS Foundation Trust\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Chest imaging is increasingly used as an alternative method for\\nscreening COVID-19, with high sensitivity compared to laboratory testing\\nmethods. AI tools have the potential to enable fast and accurate\\ndiagnosis from chest X-rays (CXR). However, several issues of image\\nquality have been identified as a limitation to the diagnostic\\nperformance of CXR, for example, in images acquired on portable\\nmachines, and where under-exposure occurs due to patient positioning or\\npatient BMI. Little is known about the impact of image-quality upon the\\naccuracy and sensitivity of AI algorithms, and we propose to investigate\\nthis, having been significantly involved in the development of the NCCID\\ndatabase, and having successfully led previous evaluations of AI tools,\\nfor example for diagnosis in breast screening.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The aim of this study is to evaluate the impact of image quality on the\\nperformance of AI models by analysing performance metrics during\\ntraining and validation using the NCCID dataset. Published, open-source\\nmodels shown to classify COVID-19 on CXR will be identified and the\\nbest-performing algorithm selected by assessing performance on the NCCID\\ntest dataset. The NCCID training and test datasets will be analysed\\nusing existing image analysis tools developed in-house at RSNFT,\\nenabling the categorisation of the NCCID dataset according to image\\nquality, and the dataset will be stratified into datasets of different\\nimage quality. The AI model will be retrained and tested on different\\ncombinations of training and test data image-quality and the impact of\\nimage-quality upon the accuracy and sensitivity of the model evaluated.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Imperial College London\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Sarcopenia is defined as the loss of skeletal muscle mass or function,\\nis primarily a disease of the elderly and a marker of frailty.\\nCurrently, physical fitness is assessed with performance status, however\\nthis score is subject to interobserver variability. There is increasing\\ninterest in the clinical importance of sarcopenia in a wide range of\\nmalignancies such as lung, breast, upper GI and colorectal cancers,\\nhowever the relationship to patient outcome in COVID-19 has not been\\nevaluated. CT provides an objective and easily reproducible assessment\\nof skeletal muscle which has been validated in cancer patients. These\\nstudies used a time consuming manual segmentation of skeletal muscle at\\nL3 (3rd lumbar vertebra level) which is not easily integrated into\\npatient care and radiology reports. The research team have already\\ndeveloped a fully automated technique for measuring sarcopenia on CT at\\nL3. The aim of the study is to evaluate an objective fully automated\\nassessment of muscle area and adiposity using artificial intelligence\\n(AI) deep learning techniques on CT to determine whether these measures\\nare linked to patient outcome in COVID-19 patients.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"University of Greenwich - School of Computing and Mathematical Sciences\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"The project deals with diagnosis of COVID-19 from chest CT scans, scan\\nseries and x-rays, through a novel Deep Learning methodology. Its main\\ntarget is to support unification of the rather fragmented field in UK\\nand internationally, where projects train DL systems over specific\\ndatasets, obtained in smaller local, or larger national frameworks, with\\nno proof of good generalisation over different datasets and different\\nclinical environments. It will achieve this through generation of a\\nportable framework for COVID-19 diagnosis, based on analysis of\\ninformation extracted from trained deep neural networks and adaptation\\nacross different data cohorts and input modalities.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"In this framework, the main systems that have been trained with chest\\nimaging examinations for diagnosis of COVID-19 in Greece will be tested\\nand adapted to the UK cohort of CT scans and x-rays. It will be examined\\nwhether the systems trained in a European country (such as Greece)\\nperform also well when applied to data from UK patients. Either, or both\\nCT scans and x-rays will be provided as inputs to these systems, for\\nsingle modal, or multi-modal COVID-19 detection. Furthermore, it will be\\ninvestigated whether this performance gets improved, if the systems get\\nadapted to the UK cohort. Finally, a unification step will be\\nimplemented, by merging both systems, i.e.,the original and the adapted\\nones, also validating the good performance of the unified system on the\\nUK data Cohort. This will illustrate the portability of the developed\\nunified model across Greece and UK and will serve as pilot that can be\\nextended with more COVID-19 diagnosis models from other parts of Europe,\\nor elsewhere.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Philips\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"As healthcare systems around the world face unprecedented stress levels, support to the clinical teams responsible for diagnosis and treatment of COVID19 patients is a priority. Recently, Philips (Royal Philips N.V.) has developed an automatic AI-based processing application (called “CT Pulmo Auto Results”, released in the USA under FDA Emergency Use Authorization and under regulatory review in EU) to assist clinical teams in quantification of the level of COVID-19 pneumonia disease burden. With the objective to further improve and monitor the performance of the application as the current pandemic unfolds, Philips is currently testing its application in collaboration with healthcare stakeholders at multiple locations around the world. As AI-based algorithms are claimed to be dependent on the training cohort Philips looks seriously to evaluate on various different cohorts. Within that scope, the National COVID-19 Chest Imaging Database (NCCID) will be used to study the performance of the application in UK patient datasets. Although approved for use in UK, the regulatory approval CE marking was not based on a UK population. In light of regulatory changes with CE marking required in future submissions and new MHRA policies coming into effect we also wish to learn from the NHSx AI lab on how to work effectively together on future R\u0026D studies in the UK using this study as an example and to work out any challenges together. Furthermore, we would explore the combination of the CT-based imaging volumetric measurements with the collected non-imaging patient data for COVID-19 pneumonia characterization with the goal to explore correlations with clinical endpoints, such as admission to Intensive Care Units or duration of stay in nursing wards.\"\n      }), \"\\n\", _jsx(_components.h2, {\n        children: \"Leeds\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"A crucial element in controlling the spread of COVID-19 is effective screening and timely treatment. Early detection of COVID-19 allows for swift intervention with isolation and appropriate use of personal protective equipment improving NHS resource allocation. Current practice commonly relies on PCR testing for confirmation of the diagnosis which takes over 24 hours for results, which can have a sensitivity as low as 60-70%. A supplementary automated tool for early detection of COVID-19 patients based on radiology could be a crucial part of addressing these issues. A wide variety of deep learning models have already been developed to detect COVID-19 in chest X-ray. However, due to a previous scarcity of COVID-19 data, many of the models the models that have been published are at high risk of bias and lack sufficient evaluation. This project will rigorously evaluate existing deep learning models with the aim of identifying the approaches most suited to detecting COVID-19 in chest X-rays. In-depth appraisal of model performances will highlight the pitfalls associated with the problem domain and help guide future work.\"\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{"title":"NCCID Project Summaries","summary":"The core of the NCCID initiative is to provide value to the public in response to the COVID-19 crisis. For this reason, NCCID wishes to share information on how the data is being utilised by approved institutions and researcherts, to inform the wider community of patients, staff and interested public.","category":"Other Information"}},"meta":{"title":"NCCID Project Summaries","summary":"The core of the NCCID initiative is to provide value to the public in response to the COVID-19 crisis. For this reason, NCCID wishes to share information on how the data is being utilised by approved institutions and researcherts, to inform the wider community of patients, staff and interested public.","category":"Other Information"}},"__N_SSG":true},"page":"/[slug]","query":{"slug":"project-summaries"},"buildId":"bmJIz1Sl1uRhvnnPo0YjL","assetPrefix":"/covid-chest-imaging-database","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>