(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[603],{8161:function(e,n,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/search",function(){return t(972)}])},972:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return h}});var a=t(5893),i=t(7294),s=t(1664),o=t(1163),r=t(3526),l=t(3423),d=[{slug:"data-access",content:'\n# Accessing the NCCID data \n\nThe data is stored in [Amazon Web Services\nS3](https://aws.amazon.com/s3/). Once your organisation has been granted\naccess, NHSX will send AWS credentials by encrypted email. The\ncredentials will allow accessing the data.\n\nWe recommend accessing the data using the [Amazon Web Services Command\nLine Interface (AWS CLI)](https://aws.amazon.com/cli/), or client\nlibraries that interact with S3 such as\n[Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\nSome examples are provided below.\n\n## Warehouse structure\n\nThe warehouse data is stored in the `nccid-data-warehouse-prod` S3\nbucket, and access is granted to different\n[prefixes](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html#object-keys).\n\nThe warehouse training data is organised into prefixes within the\n`training` prefix, based on image types (or "modality"), patient ID,\nand date as follows:\n\n``` \n# CT images & metadata\ntraining/ct/PATIENT_ID/STUDY_UID/SERIES_UID/IMAGE_UUID.dcm\ntraining/ct-metadata/PATIENT_ID/STUDY_UID/SERIES_UID/IMAGE_UUID.json\n\n# MRI images & metadata\ntraining/mri/PATIENT_ID/STUDY_UID/SERIES_UID/IMAGE_UUID.dcm\ntraining/mri-metadata/PATIENT_ID/STUDY_UID/SERIES_UID/IMAGE_UUID.json\n\n# X-ray images & metadata\ntraining/xray/PATIENT_ID/STUDY_UID/SERIES_UID/IMAGE_UUID.dcm\ntraining/xray-metadata/PATIENT_ID/STUDY_UID/SERIES_UID/IMAGE_UUID.json\n\n# Patient clinical data\ntraining/data/PATIENT_ID/status_DATE.json\ntraining/data/PATIENT_ID/data_DATE.json\n```\n\n-   The `ct`, `mri`, `xray` folders hold the\n   [DICOM](https://www.dicomstandard.org/) images of the given kind.\n-   The de-identified `Patient_ID` value is equivalent to the\n   `(0010,0020)` DICOM\n   [tag](https://www.dicomlibrary.com/dicom/dicom-tags/) from the\n   images and `Pseudonym` field from the `status_DATE.json` and\n   `data_DATE.json` clinical data files.\n-   `STUDY_UID` and `SERIES_UID` are equivalent to the `(0020,000D)` and\n   `(0020,000E)` DICOM tags in the given images.\n-   The `...-metadata` folders hold the DICOM tags exported as JSON from\n   the corresponding image file `IMAGE_UUID.dcm` into `IMAGE_UUID.json`\n   to enable quick parsing without the need to download the given image\n-   The `data` folder holds the patient medical data, `status_DATE.json`\n   files for negative results, and `data_DATE.json` file/files for\n   positive results. `DATE` is formatted as `YYYY-MM-DD`, for example\n   `2020-04-21`.\n\n\n<Alert title="Data Delay">Over time there will be more data added to the warehouse, and they will show up as new patient folders, and new image folders with new images. We expect new data will be made available approximately twice a week.</Alert>\n\n## Using the AWS Command Line Interface\n\nThe simplest way to retrieve the imaging data is using the AWS CLI:\n\n``` shell\n$ aws s3 sync s3://nccid-data-warehouse-prod/training/ct ct\ndownload: s3://nccid-data-warehouse-prod/training/ct/Covid1/1.2.3/A.B.C/x.y.z.dcm to ct/Covid1/1.2.3/A.B.C/x.y.z.dcm\n...\n```\n\nRepeating this for all the relevant directories you would download the\nlatest data and images that you don\'t have locally:\n\n``` shell\n# Remove items from this array that you don\'t want to download\nmodalities=("data" "ct" "ct-metadata" "mri" "mri-metadata" "xray" "xray-metadata")\nfor modality in ${modalities[@]}; do\naws s3 sync "s3://nccid-data-warehouse-prod/training/${modality}" "${modality}"\ndone\n```\n\nIn the above example [Bash\narrays](https://www.gnu.org/software/bash/manual/html_node/Arrays.html)\nwere used (the `modalities` variable).\n\nFor more information check the [AWS CLI\ndocumentation](https://docs.aws.amazon.com/cli/index.html). If you\nencounter any problems, open an issue on our [GitHub\nrepository](https://github.com/nhsx/covid-chest-imaging-database/issues).\n\n## Using Python and Boto3\n\nIf you are scripting access to files, we recommend using Python and\n[Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\n\nFor more information check the [Boto3\ndocumentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\nIf you encounter any problems, open an issue on our [GitHub\nrepository](https://github.com/nhsx/covid-chest-imaging-database/issues).\n\nBelow you may find examples of accessing the data in various ways with\nPython and Boto3.\n\n### Listing files\n\n``` python\nimport boto3\n\ns3 = boto3.resource("s3")\nbucket = s3.Bucket(name="nccid-data-warehouse-prod")\n\n# List the objects at a given prefix\nfor obj in bucket.objects.filter(Prefix="training/data"):\n   print(f"{obj.key}\\t{obj.size}\\t{obj.last_modified}")\n```\n\nThis will result in a list such as:\n\n``` python\ntraining/data/Covid1/data_2020-05-14.json       1416    2020-05-22 13:38:30+00:00\ntraining/data/Covid6/data_2020-05-15.json       1560    2020-05-22 13:38:31+00:00\n....\n```\n\n### Downloading image files\n\nTo download files using Boto3, if you don\'t have them locally already:\n\n``` python\nimport os\nimport boto3\n\nBUCKET_NAME = "nccid-data-warehouse-prod"\n\ndef downloadPrefixFromS3(bucketName, prefix):\n   """This function takes a remote S3 bucket and a prefix,\n   and downloads all the objects from there, that are not\n   already stored locally.\n   """\n   s3 = boto3.resource("s3")\n   bucket = s3.Bucket(name=bucketName)\n   for obj in bucket.objects.filter(Prefix=prefix):\n      key = obj.key\n      if os.path.exists(key) and os.stat(key).st_size == obj.size:\n            # If the file exists and it\'s the right size, we should be done\n            print(f"{key}: already have locally")\n            continue\n      if not os.path.exists(os.path.dirname(key)):\n            os.makedirs(os.path.dirname(key))\n      print(f"{key}: downloading")\n      bucket.download_file(key, key)\n\n# Download a specific prefix. Don\'t forget the final "/" to limit to the exact prefix\ndownloadPrefixFromS3(BUCKET_NAME, "training/mri/")\n```\n\nThe above code will create the folders corresponding to the remote\nprefixes in the current working directory as needed, and only download\nfiles that are not yet downloaded (similar to `aws s3 sync`.\n\n### Opening image files\n\nYou can also access a remote DICOM image, download into memory and open\nit with, for example with the [PyDICOM\nlibrary](https://github.com/pydicom/pydicom):\n\n``` python\nfrom io import BytesIO\n\nimport boto3\nimport pydicom\n\ns3 = boto3.resource("s3")\nbucket = s3.Bucket(name="nccid-data-warehouse-staging")\n\nimage_name = "training/xray/Covid1/1.2.3/A.B.C/x.y.z.dcm"\n\nwith BytesIO() as tmp:\n   print(f"Downloading: {image_name}")\n   bucket.Object(key=image_name).download_fileobj(tmp)\n   tmp.seek(0)\n   # Do not read the image only the metadata here.\n   # To also read the image, remove set stop_before_pixels to False\n   image_data = pydicom.dcmread(tmp, stop_before_pixels=True)\n   print(image_data)\n```\n\nThis code would result in an output such as:\n\n``` \nDownloading: training/xray/Covid1/1.2.3/A.B.C/x.y.z.dcm\n(0008, 0005) Specific Character Set              CS: \'ISO_IR 100\'\n(0008, 0008) Image Type                          CS: [\'ORIGINAL\', \'PRIMARY\', \'\', \'RT\', \'\', \'\', \'\', \'\', \'150000\']\n(0008, 0016) SOP Class UID                       UI: Digital X-Ray Image Storage - For Presentation\n...\n```\n\n### Loading a JSON file\n\nSimilarly to the image download above, JSON files can also be directly\naccessed, using the [built in Python json\nlibrary](https://docs.python.org/3/library/json.html) such as:\n\n``` python\nimport json\nfrom io import BytesIO\n\nimport boto3\n\ns3 = boto3.resource("s3")\nbucket = s3.Bucket(name="nccid-data-warehouse-prod")\n\njson_name = "training/data/Covid1/data_2020-05-14.json\n\nwith BytesIO() as tmp:\n   print(f"Downloading: {json_name}")\n   bucket.Object(key=json_name).download_fileobj(tmp)\n   tmp.seek(0)\n   json_data = json.load(tmp)\n   print(json.dumps(json_data, indent=4, sort_keys=True))\n```\n\nThe output of the above code would be similar to this:\n\n``` \nDownloading: training/data/Covid1/data_2020-05-14.json\n{\n   "Pseudonym": "Covid1",\n   ...\n}\n```',title:"Accessing the NCCID data",summary:"The data is stored in Amazon Web Services S3.  Once your organisation has been granted access, NHSX will send AWS credentials by encrypted email.  The credentials will allow accessing the data.",category:"Technical Documentation"},{slug:"home",content:"\n# National COVID-19 Chest Image Database (NCCID)\n\nThe National COVID-19 Chest Imaging Database (NCCID) is a centralised UK database containing Chest X-Ray (CXR), Computed Tomography (CT) and Magnetic Resonance (MR) images from hospital patients across the country. This is to support a better understanding of the COVID-19 virus and develop technology which will enable the best care for patients hospitalised with a severe infection. It is an initiative established by NHSX with the support of the British Society of Thoracic Imaging (BSTI), Royal Surrey NHS Foundation Trust and Faculty Science Ltd. The benefits of collecting chest imaging data are extensive. This data has the potential to enable faster patient assessment in Accident and Emergency (A&E), save Radiologists\u2019 time, increase the safety and consistency of care across the country, and ultimately save lives.\n\n## What data is collected\n\nThe NCCID collects processed digital chest X-ray, CT and MR images as well as Digital Imaging and Communication in Medicine (DICOM) header information (de-identified). Associated clinical data (de-identified) from the collection sites is also gathered. Data will be collected for all COVID-19 positively-swabbed patients, and a smaller sample of COVID-19 negatively-swabbed patients.\n\nThe categories of data collected are:\n\n-   Routine demographic data\n-   Routine cardiorespiratory assessment data at presentation\n-   All CXRs performed during evaluation for COVID-19\n-   All CT scans performed during evaluation for COVID-19\n-   All chest imaging performed in the 3 years preceding the first COVID-19-related imaging study (for COVID-19 positively-swabbed patients only)\n-   Scans (including MR) performed to investigate cardiac damage thought to be COVID-19-related\n-   Biochemical and haematological routinely collected data\n-   Outcome data, including time to mechanical ventilation, discharge and death\n   \n\nThe full list of clinical data points collected for positive and negative patients can found in the template spreadsheets on the  [Guidance And Documentation For Collection Sites](https://medphys.royalsurrey.nhs.uk/nccid/guidance.php)  page.\n\n## Data collection\n\nIf you have already joined the NCCID as a data collection site, please visit  [this website](https://medphys.royalsurrey.nhs.uk/nccid/index.php).\n\nIf you would like to join the NCCID as a data collection site, please ask your radiology department to contact  [imaging@nhsx.nhs.uk](mailto:imaging%40nhsx.nhs.uk)  and we will send them the relevant documentation.\n\nThe hospitals and trusts already contributing data to NCCID are listed below:\n\n-   [Royal United Hospitals Bath NHS Foundation Trust](https://www.ruh.nhs.uk/)\n-   [Brighton and Sussex University Hospitals NHS Trust](https://www.bsuh.nhs.uk/)\n-   [London North West University Healthcare NHS Trust](https://www.lnwh.nhs.uk/)\n-   [George Eliot Hospital NHS Trust](http://www.geh.nhs.uk/)\n-   [Cwm Taf Morgannwg University Health Board](https://cwmtafmorgannwg.wales/)\n-   [Hampshire Hospitals NHS Foundation Trust](https://www.hampshirehospitals.nhs.uk/)\n-   [Betsi Cadwaladr University Health Board](https://bcuhb.nhs.wales/)\n-   [Ashford and St Peter\u2019s Hospitals](http://www.ashfordstpeters.nhs.uk/)\n-   [Royal Cornwall Hospitals NHS Trust](https://www.royalcornwall.nhs.uk/)\n-   [Sheffield Children\u2019s NHS Foundation Trust](https://www.sheffieldchildrens.nhs.uk/)\n-   [Liverpool Heart and Chest Hospital NHS Foundation Trust](https://www.lhch.nhs.uk/)\n-   [Norfolk and Norwich University Hospitals NHS Foundation Trust](http://www.nnuh.nhs.uk/)\n-   [Royal Surrey NHS Foundation Trust](https://www.royalsurrey.nhs.uk/)\n-   [Sandwell and West Birmingham NHS Trust](https://www.swbh.nhs.uk/)\n-   [West Suffolk NHS Foundation Trust](https://www.wsh.nhs.uk/Home.aspx)\n-   [Somerset NHS Foundation Trust](https://www.somersetft.nhs.uk/)\n-   [Cambridge University Hospitals NHS Foundation Trust](https://www.cuh.nhs.uk/)\n-   [Imperial College Healthcare NHS Trust](https://www.imperial.nhs.uk/)\n-   [Oxford University Hospitals NHS Foundation Trust](https://www.ouh.nhs.uk/)\n-   [Sheffield Teaching Hospitals NHS Foundation Trust](https://www.sth.nhs.uk/)\n-   [Leeds Teaching Hospitals NHS Trust](https://www.leedsth.nhs.uk/)\n-   [University Hospitals of Leicester NHS Trust](https://www.leicestershospitals.nhs.uk/)\n\n\n<LocationsMap />\n\nAll participating hospitals and trusts will be cited in any publication resulting from the use of NCCID data.\n\n## What the data can be used for\n\nThis project aims to produce improvements in healthcare delivery for COVID-19 patients by creating a national resource for chest imaging research.\n\nThe research enabled by the chest imaging database will provide information and tools that, in the context of the COVID-19 pandemic, support:\n\n-   The determination of disease severity\n-   Clinically useful diagnosis and prognosis\n-   Patient triage and management\n-   Decision making\n\n\nWe expect the data will be used to:\n\n-   **Develop image processing software.**  _Example_: An AI model that determines COVID-19 risk score from chest X-rays.\n-   **Mathematical Modelling.**  _Example_: A mathematical model that utilises chest X-rays to determine which patients in A&E will need a ventilator during their subsequent hospital stay.\n-   **Validation of AI products.**  _Example_: A study to determine the extent to which an AI model for the diagnosis of COVID-19 trained on non-UK data retains its performance when applied on data from UK patients.\n-   **Teaching resource for radiologists.**  _Example_: A teaching environment for radiologists where learners are presented with chest images, requested to diagnose COVID-19 cases, and receive feedback on their input.\n   \n\n## How to request access to data\n\nUsers (including software vendors, academics and clinicians) requiring access to the database should fill in [this form](https://nhsx.github.io/covid-chest-imaging-database/docs/NCCID_Data_Access_Request_Form.docx) and provide a signed copy of the [Data Access Framework Contract](https://nhsx.github.io/covid-chest-imaging-database/docs/NCCID_Data_Access_Framework_Contract.docx) (if first time applying) and a [Data Access Agreement](https://nhsx.github.io/covid-chest-imaging-database/docs/NCCID_Data_Access_Agreement.docx). All documents should be sent to NHSX by contacting  [imaging@nhsx.nhs.uk](mailto:imaging%40nhsx.nhs.uk).\n\nPlease note that research groups affiliated with a hospital can only request access to NCCID data if their hospital is already a collection site.\n\n## How requests are assessed\n\nAccess requests will be assessed by a committee of experts including:\n\n-   **4 or more**  scientific advisors\n-   **4 or more**  technology advisors\n-   **2 or more**  information-governance advisors\n-   **2 or more**  patient/ethics advisors\n-   **2 or more**  system advisors to evaluate the positive impact to the NHS overall\n-   An administrator to manage the access requests\n-   A chair person (this could be any of the advisors above)\n   \n\nDecisions will be guided by the following criteria:\n\n-   Relevance to COVID-19\n-   Scientific merit of the proposed work\n-   Technical feasibility\n-   Ability to deliver the work and track record of the applicants\n-   Reasonable evidence that access to the data can benefit patients and the NHS\n-   Compliance with GDPR and NHS standards of information governance\n-   IT security\n   \n\nApplications are subject to external peer review if deemed proportionate and where the necessary expertise is not available within the committee.\n\nPlease note that data access is subject to a Data Access Agreement and a Data Access Framework Contract between the applicant and NHSX, for teaching, research and software development/validation purposes that address the COVID-19 pandemic.\n\nAny access to the data and licences to use will expire when the COVID-19 COPI (COVID-19 \u2013 Notice under Regulation 3(4) of the Health Service Control of Patient Information Regulations 2002) ceases effect.\n",title:"Overview",summary:"The National COVID-19 Chest Imaging Database (NCCID) is a centralised UK database containing Chest X-Ray (CXR),  Computed Tomography (CT) and Magnetic Resonance (MR) images from hospital patients across the country.  This is to support a better understanding of the COVID-19 virus and develop technology which will enable  the best care for patients hospitalised with a severe infection.",category:"Overview"},{slug:"nccid-collaborative",content:"\n# NCCID Collaborative\n   \nThe NCCID Collaborative includes all the researchers, clinicians and\nnurses who actively participated in contributing data to NCCID, making\nthe creation of this database possible. Contributors from each trust are\nlisted below.\n\n**NCCID Core Team**\nOscar Bennett, Dominic Cushnan, Samie Dorgham, Alberto Favaro,\nSamantha Gan, Tara Ganepola, Mark Halling-Brown, Gergely Imreh, Joseph\nJacob, Emily Jefferson, Francois Lemarchand, Neha Puri, Anastasios\nSarellas, Daniel Schofield, Smita Shetty, James Sutherland\n\n**NCCID Exteded Team**\nDaniel Alexander, Hena Aziz, Pardeep Bains, John Hurst, Rumi Kidwai,\nEmma Lewis, Gerald Lip, Peter Manser, Philip Quinlan, Rowena Reyes,\nProf. Sebire Neil, Andrew Swift, Peter Williams, Marcelle de Sousa\n\n**Royal United Hospitals Bath NHS Foundation Trust**\nDr Jonathan Carl Luis Rodrigues, Dr Helen Oliver, Dr Benjamin Hudson,\nDr Graham Robinson, Richard Wood, Annette Moreton, Katy Lomas,\nResearch & Development team\n\n**Brighton and Sussex University Hospitals NHS Trust**\nDr Nigel Marchbank, Dr Chinnoi Law\n\n**London North West University Healthcare NHS Trust**\nDr Harmeet Chana, Dr Nemi Gandy, Dr Ban Sharif, Dr Leila Ismail, Dr\nJaymini Patel, Dr Debbie Wai\n\n**George Eliot Hospital NHS Trust**\nLiz Mathers, Rachel Clark, Anisha Harrar, Alison Bettany\n\n**Cwm Taf Morgannwg University Health Board**\nDr Kieran Foley, Carla Pothecary, Stephen Buckle, Lisa Roche\n\n**Hampshire Hospitals NHS Foundation Trust**\nDr Aarti Shah, Dr Fiona Kirkham, Hannah Bown, Simon Seal, Hayley\nConnoley\n\n**Betsi Cadwaladr University Health Board**\nJenna Tugwell-Allsup, Bethan Wyn Owen\n\n**Ashford and St Peter's Hospitals**\nMary Jones, Andrew Moth, Dr Jordan Colman\n\n**Royal Cornwall Hospitals NHS Trust**\nDr Giles Maskell, Dr Daniel Kim, Dr Alexander Sanchez-Cabello, Dr\nHannah Lewis, Dr Matthew Thorley, Dr Ross Kruger, Dr Madalina Chifu,\nMr Nicholas Ashley\n\n**Sheffield Children's NHS Foundation Trust**\nSusanne Spas, Angela Bates, Peter Halson, Chris Heafey\n\n**Liverpool Heart and Chest Hospital NHS Foundation Trust**\nDr Caroline McCann, Dr David McCreavy, Dr Dileep Duvva, Dr Tze Siah,\nMrs Janet Deane\n\n**Norfolk and Norwich University Hospitals NHS Foundation Trust**\nDr. Emily Pearlman, Dr. James MacKay, Dr. Melissa Sia, Esme Easter,\nDoreen Brookes, Paul Burford, Dr. Ramona-Rita Barbara\n\n**Royal Surrey NHS Foundation Trust**\nDr Thomas Payne, Dr Mark Ingram\n\n**Sandwell and West Birmingham NHS Trust**\nDr Bahadar Bhatia, Dr Sarah Yusuf, Fiona Rotherham, Gayle Warren,\nAngela Heeney, Angela Bowen, Adele Wilson, Zahida Hussain\n\n**West Suffolk NHS Foundation Trust**\nJoanne Kellett, Rachael Harrison, Janet Watkins, Lisa Patterson\n\n**Somerset NHS Foundation Trust**\nDr Tom Welsh, Dawn Redwood, Natasha Greig, Lindsay Van Pelt, Susan\nPalmer, Kate Milne, Joanna Tilley, Melissa Alexander\n\n**Cambridge University Hospitals NHS Foundation Trust**\nAmy J Frary, Dr Judith L Babar, Dr Timothy Sadler, Dr Edward\nNeil-Gallacher\n\n**Imperial College Healthcare NHS Trust**\nSarah Cardona\n\n**Sheffield Teaching Hospitals NHS Foundation Trust**\n\n**Oxford University Hospitals NHS Foundation Trust**\nAvneet Gill, Nnenna Omeje, Claire Ridgeon, Fergus Gleeson\n\n**Leeds Teaching Hospitals NHS Trust**\nDr Annette Johnstone, Dr Russell Frood, Mr Mohammed Atif Rabani, Prof\nAndrew Scarsbrook",title:"NCCID Collaborative",summary:"The NCCID Collaborative includes all the researchers, clinicians and nurses who actively participated in contributing data to NCCID, making the creation of this database possible. Contributors from each trust are listed below.",category:"Other Information"},{slug:"other-datasets",content:"\n# Links to Other Datasets\n\n## PHOSP-COVID\n\nThe [Post-hospitalisation COVID-19 study\n(PHOSP-COVID)](https://www.phosp.org/) is collaborating with the\nNational COVID-19 Chest Imaging Database (NCCID). PHOSP-COVID is a\nnational consortium, led by experts at the University Hospitals of\nLeicester NHS Trust under the umbrella of the NIHR Leicester Biomedical\nResearch Centre. It aims to understand and improve long-term health\noutcomes for patients who have been discharged from hospital with\nconfirmed or suspected COVID-19.\n\nPHOSP-COVID has been set up and funded as a long term research study to\nrecruit 10,000 patients who have been hospitalised with COVID-19. Over\nthe course of a year, clinical assessments will track patients to gain a\ncomprehensive picture of the impact COVID-19 has had on longer term\nhealth outcomes across the UK.\n\nPHOSP-COVID will be collecting samples and scans for patients from a\nnetwork of Trusts in the UK (see\n[here](https://www.phosp.org/network/institution-trust/) for the full\nlist).\n\nPHOSP-COVID is collaborating with the NCCID initiative to ensure that\nthe same sites included in the PHOSP-COVID network are also contributing\ntowards the NCCID database. This is so that PHOSP-COVID researchers are\nable to access important data already collected for patients via the\nNCCID study in order to accompany the longitudinal data PHOSP-COVID are\ncollecting for patients.\n\n<Alert title=\"Important information for data collection sites\">\n   If you are contacted by the PHOSP-COVID study to upload data but are not yet contributing to the NCCID, we would ask that you follow the instructions here to ensure you are contributing to both studies.\n</Alert> \n\n## ISARIC\n\nThe [International Severe Acute Respiratory and emerging Infection\nConsortium](https://isaric.org/) (ISARIC) was founded in 2011 to prevent\nillness and deaths from infectious disease outbreaks. It is a global\nfederation of clinical research networks, providing a proficient,\ncoordinated and agile research response to outbreak-prone infectious\ndisease.\n\nThis consortium is responding to the current COVID-19 outbreak by\ncreating tools for investigators to collect and store data in a\nstandardised way and has supported clinical trials of treatments. One of\nthese tools, the 'Clinical Characterisation Protocol' (CCP), has been\nco-developed by HDR UK members, in consultation with colleagues at the\nWorld Health Organisation.\n\nThe CCP sets out how data and biological samples from patients with\nCOVID-19 should be collected, regardless of where in the world they are.\nIt's the product of many years of discussion among international\ninvestigators from a wide range of scientific and medical disciplines.\nWork to develop this protocol started in response to Middle Eastern\nRespiratory Syndrome coronavirus (MERS-CoV) in 2012-2013, Influenza H7N9\nin 2013, viral haemorrhagic fever (Ebolavirus) in 2014, Monkeypox &\nMERS-CoV in 2018 and Tick-borne encephalitis virus (TBEV) in 2019. It is\nnow being used for COVID-19 .\n\nISARIC-4C will augment the aforementioned datasets, which have played a\ncentral role in the UK's research response to COVID-19, with imaging\ndata from the NCCID. This will support improvements in the\nunderstanding, diagnosis and prognosis of the disease through the\navailability of data that comprises a wide range of variables such as\nclinical measurements, 'omics' assays, and radiology scans.",title:"Links to Other Datasets",summary:"The Post-hospitalisation COVID-19 study (PHOSP-COVID) is collaborating with the National COVID-19 Chest Imaging Database (NCCID). PHOSP-COVID is a national consortium, led by experts at the University Hospitals of Leicester NHS Trust under the umbrella of the NIHR Leicester Biomedical Research Centre.",category:"Other Information"},{slug:"performance-assessment-call",content:"\n# Performance Assessment Call\n\n<Alert title=\"Call for AI driven COVID-19 models\">\n   Performance assessment using the National COVID-19 Chest Imaging Database\n</Alert> \n\n## Introduction\n\nThe [National COVID-19 Chest Imaging Database\n(NCCID)](https://nhsx.github.io/covid-chest-imaging-database/) was\ncreated as part of the NHS AI Lab's response to the coronavirus\npandemic. The NCCID is currently the largest database of medical\nimages from COVID patients in the UK, and a world-class initiative\naccelerating the development of AI technologies. This database will be\nan important resource to train and assess the performance of AI\ntechnologies that can be used as part of the ongoing response to\nCOVID-19. The majority of scans collected by the NCCID are chest\nX-rays and come from people with and without COVID-19. The database\nalso holds some additional data about the patients who tested\npositive, such as their gender and age. A portion of these images and\nclinical data points has been set aside as 'unseen' for the purpose of\nassessing the performance and fairness of COVID-19 related AI models.\n\nThe NHS AI Lab is now inviting research institutions and technology\ncompanies that have been developing AI models **using COVID-19 chest\nimaging data** to apply to have their model's performance assessed on\nthe NCCID's unseen dataset. The assessment will be commissioned by\nNHSX to independent assessors, who will carry out the work with NHSX\ninvolvement and supervision.\n\n## The importance of performance assessment on an unseen, representative dataset\n\nThe performance of AI models is linked to the characteristics of the\ndata that they have been trained on, and those they encounter once put\ninto clinical practice. This is the source of an important concern\nabout the use of AI in healthcare: how to ensure that the claims made\nabout a model will prove to be the case in the real world, where the\ndata can be different from that used to develop it.\n\nAssessing the performance of AI models on a dataset that is\nrepresentative of the UK population reduces the potential for bias and\nprovides NHS commissioners and healthcare regulators with the evidence\nto judge the safety, efficacy, and generalisability of AI models\nbefore they are used in clinical practice. The NHS AI Lab has been\nworking closely with NHS commissioners, regulators and end-users to\ndefine this process, and this performance assessment exercise will\nhelp to inform how this process may be carried out in the future.\n\n## How do I apply?\n\nBefore applying, please ensure you are submitting an application for\nan AI technology developed using chest imaging data that addresses\nneeds connected to COVID-19.\n\nApplications from technology developers with products that have\nalready achieved ISO13485 certification or other Quality Management\nSystem (QMS) certification are particularly welcome. **This is not a\nprerequisite for a product to be eligible for this assessment.**\nHowever, please note that it is a prerequisite of both the derogation\nand standard pathways for gaining the UKCA/CE mark.\n\nIf you would like to apply, please complete this [application\nform](https://forms.gle/bcerY7XQcxeZj4Lg9/) . If you have any\nquestions, please contact us on <imaging@nhsx.nhs.uk>. **The\napplication process is open from now and will close at 1pm on 28 May\n2021.** This will be followed by a 3-week review process by a pool of\nexpert reviewers, by the end of which you will receive feedback on the\noutcome of your application.\n\n## What will I receive at the end of the assessment?\n\nThe technology developer will receive a written report from the\nexternal assessors that documents how the AI model in question\nperformed against the defined performance criteria. This will include\nan assessment of model performance (sensitivity, specificity etc.),\nand clinical applicability that can be used as evidence to support\napplications to the MHRA for derogation of UKCA/CE marking or via\nstandard conformance assessment processes.\n\nIn addition, depending on the outcome of the exercise, NHSX can\nsupport technology developers in identifying and making introductions\nto NHS trusts which have expressed an interest in commissioning new AI\ntechnologies.\n\n## Is this a route to regulatory conformance?\n\nNo, it is important to note that this process does not replace the path\nto achieve UKCA/CE/UKNI marking. This is considered to be a validation\nstudy and does not qualify as a clinical investigation for the purposes\nof clinical evaluation. In the context of bringing AI models to fruition\nas part of the COVID-19 response, the developers undergoing the proposed\nperformance assessment process will, depending on the outcome of the\nexercise, be able to generate high quality evidence that their model\nperforms as intended, which they can submit to the Medicines and\nHealthcare products Regulatory Agency (MHRA) to support their\napplication for derogation (for more information please visit\n[Exemptions from Devices regulations during the coronavirus\noutbreak](https://www.gov.uk/guidance/exemptions-from-devices-regulations-during-the-coronavirus-covid-19-outbreak#exemptions-for-all-other-kind-of-medical-device/)\non the Gov.uk website).\n\nAlternatively, standard routes to conformity under the device\nregulations remain open. Evidence generated via the proposed\nperformance assessment process may form part of a standard regulatory\nsubmission. For more information please visit [How to comply with the\nlegal requirements in Great\nBritain](https://www.gov.uk/guidance/medical-devices-how-to-comply-with-the-legal-requirements/)\non the Gov.uk website.\n\n## What will this exercise involve for the technology developer?\n\nThe NHS AI Lab will be using independent assessors to run the\nexercise, and assess the performance of the technology developer's AI\nmodel. By doing this, NHSX aims to source deep subject matter\nexpertise on both a technical and clinical level, in order to ensure\nthat the exercise is carried out effectively and objectively. The\nvalidation will be performed within a cloud-computing infrastructure\nprovided by NHSX, containing the NCCID unseen dataset. This will\nguarantee the dataset remains in a safe and secure location, and\nmitigate the risk of data being shared. The NHS AI Lab's Programme\nManagement Office will oversee the process.\n\n## How will the performance of an AI model be assessed?\n\nThe assessment will be conducted on retrospective data and the\nfollowing steps will take place:\n\n-  The external assessors will prepare an analysis plan, including\n   performance criteria, before the start of the assessment. To support\n   this, NHSX will facilitate access to a network of regulators,\n   subject matter experts and end users.\n-  The technology developer will need to provide precise indications\n   of use for their product. These will be the mechanism by which the\n   performance criteria are tailored to the AI model, and the only\n   input of the developer towards them.\n-  Depending on the AI model to be assessed, it may be necessary for\n   the assessors to source additional data externally and curate the\n   resources. This is to ensure a dataset large and representative enough\n   to perform an effective assessment. Note that pseudonymised data that\n   does not contain patient identifiable information will be used\n   throughout this process. Due to the continuous growth of the NCCID, the\n   unseen dataset and any complementary data will be versioned\n   appropriately to ensure a fair comparison between models, if required.\n\n\n## What infrastructure will be provided for the assessment process?\n\nThe computational environment to run the exercise will be provided by\nNHSX via an AWS sub account on the existing NCCID infrastructure. The\ninfrastructure will have the following:\n\n-  Access to the NCCID unseen dataset will be in the form of an S3\n   bucket. The provision of this infrastructure by NHSX is to ensure\n   the assessment is carried out within a secure environment that meets\n   the requirements set by information governance. Please note that, at\n   no time, will the technology developer have access to the NCCID\n   unseen dataset.\n-  Any additional infrastructure required to run the validation\n   process will be hosted within this computational environment, but\n   will be developed by the external assessors. This may include\n   infrastructure that enables the following:\n-  Deployment of the AI software by the technology developer, such\n   that the technology developer can then be locked out whilst the\n   external assessment is performed.\n-  Additional security measures to ensure that both the data and the\n   AI software are protected.\n-  Assessment of the AI Product against defined performance metrics. \\|\n   Note that the deployment of the AI software for assessment will be\n   achieved through coordination between the external assessors and the\n   technology developer. We anticipate the AI model may be run on a virtual\n   machine, and therefore may need to be containerised using technologies\n   such as Docker.\n\n\n## How will the technology developer's intellectual property be protected?\n\nAs part of the assessment process:\n\n-  All members of the performance assessment exercise team, including\n   the external assessors, will be bound to confidentiality by\n   contractual arrangements. Where needed, additional Non-Disclosure\n   Agreements (NDAs) will be put in place.\n-  The computing infrastructure, on which the AI model is deployed,\n   will ensure that the relevant access controls are in place to\n   protect the Intellectual Property (IP) of the technology developer.\n-  Under no circumstances will NHSX or its agents make claims to\n   developer IP, and this will be captured in the contractual\n   arrangements prior to commencing the exercise.\n\n\n## How long will the assessment process take?\n\nThe process end-to-end will take approximately 12-16 weeks to\ncomplete, depending on the complexity of the model deployment and\nanalysis.\n\nHow many AI models do you intend to assess? This will depend on the\nnumber of applications received and the strength of the proposals.\n\n## How much will this assessment cost me?\n\nNHSX will bear the cost of the performance assessment exercise.\n\n## How will applications be assessed?\n\nApplications will be scored against a set of defined criteria for each\nof the following categories:\n\n-  NHS importance\n-  Technical feasibility\n-  Financial viability\n\nFurther details for the above criteria are included in the Application\nForm.\n\nApplications will be assessed by expert peer reviewers and an\nappointed committee consisting of technical and clinical advisors.",title:"Performance Assessment Call",summary:"The National COVID-19 Chest Imaging Database (NCCID) was created as part of the NHS AI Labs response to the coronavirus pandemic. The NCCID is currently the largest database of medical images from COVID patients in the UK, and a world-class initiative accelerating the development of AI technologies.",category:"Other Information"},{slug:"project-summaries",content:"\n#  NCCID Project Summaries\n\nThe core of the NCCID initiative is to provide value to the public in\nresponse to the COVID-19 crisis. For this reason, NCCID wishes to share\ninformation on how the data is being utilised by approved institutions\nand researcherts, to inform the wider community of patients, staff and\ninterested public.\n\nBelow is a list of the projects currently ongoing.\n\n## University College London\n\nUniversity College London plans to store the NCCID data in a highly\nsecure XNAT repository to enable imaging-based research at UCL Centre\nfor Medical Image Computing (CMIC). In particular, researchers at CMIC\nwill use these data to build artificial intelligence models to\nautomatically detect COVID-19 patients based on their CT or X-ray\nimages, such that, in the future, these images can be screened\nautomatically before doctors read them. This will significantly save\ntime in managing future outbreaks. The research also involves building\ncomputational models to analyse the outcomes for those with confirmed\nCOVID-19 diagnosis, predicting best management for individual patients.\nThese predictions may shorten their hospital stay, reduce complications\nand even save lives. Finally, the project will investigates methods to\ndeploy these developed models to local hospitals quickly and safely.\n\n## University of Cambridge\n\nIt is strongly believed that early detection of COVID-19 and\nintervention leads to lower Covid-19 mortality because it enables\ndisease treatment via oxygen therapy and control of spread via\nisolation. The diagnosis of COVID-19 must be confirmed by\nreverse-transcription polymerase chain reaction (RT-PCR) or gene\nsequencing for respiratory or blood specimens. However, testing the\ngeneral population is proving to be very challenging because of various\nreasons including limitations of sample collection and transportation,\nkit performance and availability, limitations in capacity, etc.\n\nChest scans could include x-rays, CT and MRI scans. Chest CT scans are\nused to examine lung tissues and often used for further investigation\nafter an abnormal chest x-ray. Chest MRI scans provide a detailed\npicture of the chest wall, heart, and blood vessels. These scans are\ncarried out routinely for a variety of medical reasons, including\npreparation for surgery, annual follow-ups, accident and emergency, etc.\nThe creation of computer systems that can automatically process these\nscans to detect and identify signs of Covid-19 can provide added value\nfor the NHS with no significant additional burden on staff, resources,\noperational costs, etc. The development of these systems require the\nimplementation of cutting-edge image processing and artificial\nintelligence technologies.\n\nX-ray images and CT scans can also be useful in monitoring the\nprogression of Covid-19 patients as they can reveal if their lungs are\nfilled with sticky mucus that can lead to breathing problems and provide\na benchmark for comparisons with previous scans.\n\nThis project aims to find the visual signatures of Covid-19, as they\nappear in chest scans, that can lead to accurate diagnostic and\nprognosis for use in hospital settings. Automated imaging algorithms,\naided by advanced artificial intelligence techniques, can detect some of\nthe abnormal features appearing in these scans, such as ground glass\npatterned areas, Ground glass, Crazy paving, Vascular dilatation,\nTraction Bronchiectasis. These features are generally not specific to\nCovid-19 and could be seen with other infections. Hence, it is important\nto develop AI techniques to aid the imaging analysis to increase the\naccuracy of diagnostic.\n\n## University of Bradford\n\nCoronavirus Disease 2019 (COVID-19) is highly contagious, and severe\ncases can lead to pneumonia and ultimately death. The diagnosis can be\nconfirmed by laboratory testing; however, the test has low sensitivity\nwhich leads to late diagnosis and treatment. Chest X-rays and CT scans\nprovide valuable diagnostic and monitoring information that can\ncomplement the laboratory and clinical data. In this project, we propose\nto develop an open-source artificial intelligence tool that combines\nchest imaging data and clinical data to support the diagnosis, triaging\nand prognosis for COVID-19 in the UK. This will make clinical decisions\nmore efficient, accurate, timely, and potentially cheaper, leading to\nbetter patient outcomes.\n\n## Aidence\n\nChest CT scans are used in hospitals across the globe to image the\nseverity of COVID-19 lung involvement and guide the appropriate patient\nmanagement. Artificial intelligence (AI) designed for radiologists can\nincrease the speed of reporting on these scans and support timely\npatient triaging.\n\nAidence has set-up an international consortium, ICOVAI, to create an AI\nsolution for COVID-19 on chest CTs. The consortium is a collaboration\nbetween clinical centers, hospitals, AI companies, and distribution\npartners.\n\nICOVAI's AI solution will automatically detect COVID-19 on chest CTs and\nassess the extent of lung tissue affected. Its quantitative analysis can\nbe used to guide hospital management, such as bed capacity on wards, or\npredicting the need for ICU care.\n\nThe consortium aims to reduce the workload and pressure that the medical\nstaff are facing during the pandemic. The software will be particularly\nuseful when test kits are absent or inconclusive, and when radiologists\nare unavailable or lack specific COVID-19 training.\n\nTo train a well-performing model, ICOVAI is using high-quality datasets\nfrom diverse CT scanners, hospitals, and countries. The patient data is\nanonymised and processed in line with the GDPR. The product will comply\nwith the Medical Device Regulation (MDR), 2017/745, to ensure clinical\nsafety and quality.\n\nThe AI solution will be made available not-for-profit for the NHS and\nEuropean hospitals. The project is backed by the EU.\n\n## City Data Science Institute\n\nThe City Data Science Institute are using the NCCID dataset to develop\nartificial intelligence systems that offer explainable decision making.\nMore specifically, we are investigating the key radiological findings of\nCovid-19, how this can change over time, and how this differs from other\ndisease findings upon a chest X-ray. Using state-of-the-art generative\nnetworks, we aim to learn more about the Covid-19 disease process and\nfacilitate medical decision making.\n\nThe chest X-ray is a readily available investigation and is useful in\nthe identification, severity assessment and monitoring of Covid-19. It\nis more readily available than CT scanning and able to exclude other\nimportant conditions that may present. The use of AI to assess chest\nX-rays can facilitate medical staff and improve patient outcomes.\n\nWe have begun using a particular type of artificial intelligence model\nthat is able to learn what an X-ray should appear like if it were to be\nhealthy or more diseased. This will help the research community learn\nabout subtle disease features and can contribute to more accurate and\nquicker automatic diagnostics. One of our main goals is for our system\nto offer a counterfactual explanation as to why the artificial\nintelligence has made certain decisions. This is vital in developing\nsafe and effective AI.\n\n## Medical Analytica Ltd\n\nTo test, evaluate and further finetune a software which can\nautomatically analyse Chest X-ray images to identify absence or presence\nof features of COVID-19 infection. The software can detect other lung\nconditions such as pneumonia caused by viral or bacterial infections.\nThe software is being further developed to identify other key conditions\nsuch as lesion and enlarged heart. The software utilises a number of\nmathematical models for image analysis and is capable of offering a high\nconfidence classification with minimum false positives or false\nnegatives.\n\nUltimate objective is integrating it into the NHS radiology reporting\nworkflow to provide a prompt computer aided prediction alongside the\nradiologist's own report. By providing an extra layer of support to the\nclinical team, patient triage and access to appropriate treatment can be\nspeed up. Saving time, resources and most importantly, improving patient\nexperience.\n\nOther application of the software is to provide preliminary / indicative\nprediction to the primary care team in remote locations and community\nhospitals to assist in identifying in the community cases which may need\nurgent specialist attention in main hospitals.\n\n## Universities of Brighton, Oxford, Glasgow, Lincoln and Sheffield\n\nMembers of this collaboration were instrumental in winning first place\nin\n'[Coronahackathon](https://devpost.com/software/europa-mapp-predicting-stopping-covid19-waves-pandemics)'\nApril 2020, for the development of Machine Learning (ML) and Artificial\nIntelligence (AI) to predict patients with SARS-CoV-2 virus using full\nblood count results. SARS-CoV-2 positive patients exhibit a\ncharacteristic change in different parameters measured in simple and\nrapid blood tests to a high accuracy, predicting the virus in regular\nwards (93-94%) and those in the community (80-86%).\n\nOur project will validate these initial results and enable use in\ncurrent hospital practice to screen patients and identify those needing\nfull diagnosis for SARS-CoV-2. Expertise in chest images, blood science\nand modelling ML and AI will develop an innovative tool to upscale\nscreening to identify individuals for full rt-PCR testing of the virus\npotentially up to one week earlier than rt-PCR, which will allow much\nfaster release of the country (and the world) from lockdown, protection\nagainst future waves and future pandemics.\n\n## Ashford and St Peter's Hospitals NHS Foundation Trust\n\nChest X-rays are often one of the first tests used to help guide doctors\nwith deciding how likely a patient is to have COVID-19 and also how\nsevere the infection is. We are aiming to see how accurate chest X-rays\nare for detecting COVID-19 and telling doctors how severe the disease\nis. We plan to answer this by having doctors specialising in X-rays\nassess chest X-rays of patients in the national COVID-19 imaging\ndatabase and then compare this assessment to clinical details, such as\nif they had COVID-19 and how well they did in hospital. We hope this\nwill give us a better understanding of chest X-ray accuracy in COVID-19\nand appearances that are linked to COVID-19 or more severe infection. We\nalso additionally aim to use Neural networks (advanced computational\nalgorithms) on the chest X-rays in the database to see if these can be\nused to automatically detect COVID-19 in chest X-rays. This research\nwill hopefully one day help with the development of clinical algorithms\nand technology that can be used to speed up chest X-ray assessment for\nCOVID-19.\n\n## Behold.ai\n\n[Behold.ai](https://behold.ai/) is currently operating existing services\nwithin the NHS for the triage of chest X-rays based on the presence of\nabnormalities, as determined by artificial intelligence algorithms. In\nthis study Behold.ai aims to achieve two key goals.\n\nFirst, we aim to validate that an algorithm developed for the general\ndetection of abnormalities on plain-film chest X-rays can identify novel\nforms of abnormality (such as COVID-19) despite being developed prior to\nthat pathology's initial presentation (in this case, prior to February\n2020). We propose that this will show that the use of existing AI-based\npatient triage can assist healthcare systems in the efficient use of\nresource and radiological capacity during high stress periods such as\npandemic flu, even when novel pathologies are present.\n\nSecondly, in recognition of the increased utilisation of AI across\nhealthcare sectors, we aim to establish a set of best practices for\nrapidly and regularly updating clinically deployed algorithms in order\nto enable efficient 'learning' of the characteristics of novel\npathologies. This will be validated by the ability of existing chest\nX-ray models to learn the characteristics of COVID-19 as demonstrated in\nthe NCCID. We suggest that this work will ensure that the implementation\nof AI into health systems improves future pandemic preparedness as well\nas maximising responsiveness to population health.\n\n## The Royal Surrey NHS Foundation Trust\n\nChest imaging is increasingly used as an alternative method for\nscreening COVID-19, with high sensitivity compared to laboratory testing\nmethods. AI tools have the potential to enable fast and accurate\ndiagnosis from chest X-rays (CXR). However, several issues of image\nquality have been identified as a limitation to the diagnostic\nperformance of CXR, for example, in images acquired on portable\nmachines, and where under-exposure occurs due to patient positioning or\npatient BMI. Little is known about the impact of image-quality upon the\naccuracy and sensitivity of AI algorithms, and we propose to investigate\nthis, having been significantly involved in the development of the NCCID\ndatabase, and having successfully led previous evaluations of AI tools,\nfor example for diagnosis in breast screening.\n\nThe aim of this study is to evaluate the impact of image quality on the\nperformance of AI models by analysing performance metrics during\ntraining and validation using the NCCID dataset. Published, open-source\nmodels shown to classify COVID-19 on CXR will be identified and the\nbest-performing algorithm selected by assessing performance on the NCCID\ntest dataset. The NCCID training and test datasets will be analysed\nusing existing image analysis tools developed in-house at RSNFT,\nenabling the categorisation of the NCCID dataset according to image\nquality, and the dataset will be stratified into datasets of different\nimage quality. The AI model will be retrained and tested on different\ncombinations of training and test data image-quality and the impact of\nimage-quality upon the accuracy and sensitivity of the model evaluated.\n\n## Imperial College London\n\nSarcopenia is defined as the loss of skeletal muscle mass or function,\nis primarily a disease of the elderly and a marker of frailty.\nCurrently, physical fitness is assessed with performance status, however\nthis score is subject to interobserver variability. There is increasing\ninterest in the clinical importance of sarcopenia in a wide range of\nmalignancies such as lung, breast, upper GI and colorectal cancers,\nhowever the relationship to patient outcome in COVID-19 has not been\nevaluated. CT provides an objective and easily reproducible assessment\nof skeletal muscle which has been validated in cancer patients. These\nstudies used a time consuming manual segmentation of skeletal muscle at\nL3 (3rd lumbar vertebra level) which is not easily integrated into\npatient care and radiology reports. The research team have already\ndeveloped a fully automated technique for measuring sarcopenia on CT at\nL3. The aim of the study is to evaluate an objective fully automated\nassessment of muscle area and adiposity using artificial intelligence\n(AI) deep learning techniques on CT to determine whether these measures\nare linked to patient outcome in COVID-19 patients.\n\n## University of Greenwich - School of Computing and Mathematical Sciences\n\nThe project deals with diagnosis of COVID-19 from chest CT scans, scan\nseries and x-rays, through a novel Deep Learning methodology. Its main\ntarget is to support unification of the rather fragmented field in UK\nand internationally, where projects train DL systems over specific\ndatasets, obtained in smaller local, or larger national frameworks, with\nno proof of good generalisation over different datasets and different\nclinical environments. It will achieve this through generation of a\nportable framework for COVID-19 diagnosis, based on analysis of\ninformation extracted from trained deep neural networks and adaptation\nacross different data cohorts and input modalities.\n\nIn this framework, the main systems that have been trained with chest\nimaging examinations for diagnosis of COVID-19 in Greece will be tested\nand adapted to the UK cohort of CT scans and x-rays. It will be examined\nwhether the systems trained in a European country (such as Greece)\nperform also well when applied to data from UK patients. Either, or both\nCT scans and x-rays will be provided as inputs to these systems, for\nsingle modal, or multi-modal COVID-19 detection. Furthermore, it will be\ninvestigated whether this performance gets improved, if the systems get\nadapted to the UK cohort. Finally, a unification step will be\nimplemented, by merging both systems, i.e.,the original and the adapted\nones, also validating the good performance of the unified system on the\nUK data Cohort. This will illustrate the portability of the developed\nunified model across Greece and UK and will serve as pilot that can be\nextended with more COVID-19 diagnosis models from other parts of Europe,\nor elsewhere.\n",title:"NCCID Project Summaries",summary:"The core of the NCCID initiative is to provide value to the public in response to the COVID-19 crisis. For this reason, NCCID wishes to share information on how the data is being utilised by approved institutions and researcherts, to inform the wider community of patients, staff and interested public.",category:"Other Information"},{slug:"resources",content:'\n#  Resources for Data Users\n\n## Data cleaning pipeline and guidelines\n\nWe have created a [data cleaning\npipeline](https://github.com/nhsx/nccid-cleaning) in the form of a\nPython library, which can be used to clean the accompanying clinical\ndata to the images. This will help with:\n\n-  Correcting format errors\n-  Removing anomalous data\n-  Remapping categorical values to standardised categories\n-  xtracting values embedded within strings\n-  Merging data under old or mis-typed column headers into the\n   new/correct fields\n-  Standardising the scales of some clinical variables\n\n\nIn addition, we have created guidelines for interpreting the clinical\ndata, compiled in [this spreadsheet](/docs/NCCID_schema_compliance_v2.1.xlsx). This will help with:\n\n-  Understanding what the expected data format is for each field\n-  Highlighting where there are known erroneous entries for each field\n-  Recommending remedial actions for erroneous entries within each field\n\n\nAn [additional spreadsheet](/docs/NCCID_site_specific_units.xlsx) contains information on submitting sites that use\nmeasurement units for various clinical variable fields that is different\nfrom the overview of the above schema description. This will help with:\n\n-  Transforming clinical measurements on the same range\n\n\nPlease note that this sheet contains only a subset of potential\nsubmitting centres, and a subset of clinical variables. Furthermore,\nresponses for these submitting centres may only represent a subset of\ntheir hospital sites, where units might vary from hospital to hospital.\nThe information presented here should only serve as a guide, and always\nbe checked against values to ensure they are sensible. For some fields\nyou might have to make decisions on data cleaning and potentially drop\nvalues that you think are outside the plausible range or entered\nincorrectly.\n\n---\n\n## Frequently Asked Questions\n\nThis is a list of Frequently Asked Questions with regards to the NCCID\ndataset content and usage. Feel free to suggest new entries!\n\n### How often is new data uploaded to the database?\n\nIt varies but we are aiming for a new data release every week.\n\n### What is the "Final COVID Status" determined by? We\'re seeing patients with two negative PCRs with a positive final COVID status.\n\nThe Final COVID Status is the final status that is available for each\npatient. The fact that there are patients with multiple negative swab\nresults and the final status which is positive is an example of what\nhappens sometimes in practice: patients might get tested several times\nproducing negative results, and then finally result positive. This might\nbe because sometimes tests are not accurate or because patients fell ill\nbetween the initial and the final test.\n\n### Is COVID CODE = Normal the equivalent of "regular" Covid-19 or is it non-Covid-19?\n\n`COVID CODE = Normal` refers to the cases where the X-Rays do not show\nsigns of Covid-19, this might be because the patient does not have it or\nbecause the patient has only very mild symptoms.\n\n### What are the CXR severity scores?\n\nThe severity scores associated with the chest X-Ray studies are\nsubjective descriptions provided by the radiologist reviewing the\nimages, on a scale of three severity levels (Mild = 1, Moderate = 2,\nSevere = 3).\n\n### Is the CXR severity score only available for the first two X-Ray studies?\n\nYes,the severity information is only available for the first two X-Ray\nstudies for each patient.\n\n### How can I match the clinical data points to the corresponding imaging scan?\n\nThe temporal information should help you match the information in the\nsheet with the relevant imaging study: `Date of 1st CXR` and\n`Date of 2nd CXR` are the dates in which the first two X-Ray scans were\ntaken and correspond to the two severity values, the time information in\nthe X-Ray\'s DICOM should then allow you to identify the imaging scans\nthat match with those dates.\n\n### Date format seems to be inconsistent across date variables (some are in US format and some are in UK format). Why is this? Is there a pattern?\n\nYes, it is true that the date format is not consistent across all\nvariables, but it should be consistent within each single variable (i.e.\nif it is UK format, all entries for that variable are in UK format).\n\nThe dates of the Date of acquisition of 1st RT-PCR and Date of\nacquisition of 2n RT-PCR are in US format, however we have seen there\nare a few instances where some sites have inputted additional text in\nthese fields which will require a small amount of cleaning (e.g.\n`Date of 1st CXR` with value `[TEXT] - 2020-03-27`).\n\nAll other dates should be in UK or ISO format.\n\n### Have any of the dates been changed systematically as part of the anonymisation process? Or are the dates in the DICOM files and the clinical variables the actual dates of scans and tests?\n\nMost dates in the DICOM files have been offset. The excludes the\nAcquisition date (if present) and the Study Date, so these can be used\nto identify the time of scan. In addition, the patient\'s DOB has been\nreset to the year of birth followed by 0101. The dates in the clinical\ndata have not been touched.\n\n### There are cases where patients have multiple JSON files. Why is this? Which one is the correct one?\n\nSituations with patients who have multiple JSON files can occur when the\nsites that contribute data to NCCID have uploaded data, then\nrevised/corrected and then re-uploaded it. We are not currently\nover-writing files, as it would make data management harder. We suggest\nthat for each patient you utilise the latest JSON file that you have\navailable.\n\nFinally, there can also be cases in which the same patient went to two\ndifferent hospitals, and for which images have been received from two\ncentres separately. In similar situations, the older JSON files should\nbe considered.\n\n### How can I combine the clinical data into a single table/dataset, selecting only the most recent "data" and/or "data" files for each patient?\n\nThe development team prepared a tool to help you to aggregate JSON\nmetadata and convert the results to CSV files. Please check [this\nrepository](https://bitbucket.org/scicomcore/nccid-data-to-csv/), where\nthe README contains all the relevant information and the relevant\ndownload links.\n\n### How do I tell if the clinical data files are for positive and negative patients?\n\nThere are two files, with `status` and `data` in the filename, that can\nbe used to differentiate between Covid-19 positive and negative\npatients. Negative patients only have a `status` file, this is because\ndata providers were told to only submit the minimum information for the\ncontrol cohort, to make it easier for them. Positives can be identified\nby the presence of a `data` file which contains relevant clinical\ninformation, such as their medical history. Some positive patients will\nhave both files, but their status file can be ignored.',title:"Resources for Data Users",summary:"We have created a data cleaning pipeline in the form of a Python library,  which can be used to clean the accompanying clinical data to the images. This will help with:",category:"Technical Documentation"},{slug:"stats",content:'\n<Stats />\n\n<Alert title="Important note">\n   The above table contains information on the training\n   data that is shared with data access users. The NCCID initiative\n   reserves a large percentage of the data as unpublished in order to\n   support testing and independent validation of AI models.\n</Alert>',title:"Training data statistics",category:"Other Information",description:"Below you can find high level statistics of the data available in the training set of the database",formatting:!1,offwhite:!0}];function h(){var e=(0,o.useRouter)().query.q,n=(0,i.useMemo)((function(){return e&&d.filter((function(n){return n.title.toLowerCase().includes(e.toLowerCase())||n.content.toLowerCase().includes(e.toLowerCase())}))}),[e]);return(0,a.jsxs)(l.Z,{noPagination:!0,children:[(0,a.jsx)(r.Z,{title:"Search Results",description:n?"Your search returned ".concat(n.length," results"):"No results found"}),n&&(0,a.jsx)("div",{className:"space-y-6",children:n.map((function(e){return(0,a.jsx)(s.default,{href:"/".concat(e.slug),children:(0,a.jsxs)("a",{className:"block",children:[(0,a.jsx)("h3",{className:"text-lg font-medium text-nhsuk-text mb-1",children:e.title}),(0,a.jsx)("p",{className:"text-nhsuk-secondary-text",children:e.summary})]})},e.slug)}))})]})}}},function(e){e.O(0,[805,612,774,888,179],(function(){return n=8161,e(e.s=n);var n}));var n=e.O();_N_E=n}]);